{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T07:33:29.316039Z",
     "start_time": "2025-02-10T07:33:28.763015Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import mne # reads edf format\n",
    "import glob\n",
    "import random\n",
    "import re\n",
    "import wfdb # waveform database library wfdb.rdann reads annotation of physiology annotated data in ECG, EEG etc\n"
   ],
   "id": "9e3119ec8ee92a61",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Objective:\n",
    "#### Signal Extraction\n",
    "\n",
    "Codes extensively modified from work by [Mashahiro Goton](https://www.kaggle.com/code/hemangjindal/chb-mit-eeg-dataset-my-notebook#CHB-MIT-eeg-dataset-seizure-detection-demo). \\[Online] [Accesssed on 20 October 2024].\n",
    "\n",
    "EDfToNpy class contains:\n",
    "1. read_efd - read edf formatted seizure file. Identify parameters for creating numpy arrays. Ensure correct channels and calculate samples of seizure and non seizure files.\n",
    "2. extract_edf - create appropriate numpy arrays using arguments obtained from read_edf method. Copy data and labels to numpy array, then save to file as npy format.\n",
    "3. show_EEG - display EEG\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "#### Signal Extraction\n",
    "\n",
    "The code presented in this notebook is extensively modified from work by [Mashahiro Goton](https://www.kaggle.com/code/hemangjindal/chb-mit-eeg-dataset-my-notebook#CHB-MIT-eeg-dataset-seizure-detection-demo).\n",
    "**[Online] Accessed on 20 October 2024.**\n",
    "\n",
    "#### Overview of the `EdfToNpy` Class\n",
    "\n",
    "The `EdfToNpy` class provides functionalities for processing EEG data from EDF files, specifically from the CHB-MIT dataset. It includes the following methods:\n",
    "\n",
    "1. **`read_edf`**:\n",
    "   - Reads EDF-formatted seizure files.\n",
    "   - Identifies parameters for creating NumPy arrays, ensuring correct channel mapping.\n",
    "   - Calculates samples for both seizure and non-seizure files.\n",
    "\n",
    "2. **`extract_edf`**:\n",
    "   - Creates NumPy arrays using the parameters obtained from the `read_edf` method.\n",
    "   - Copies EEG data and corresponding labels to NumPy arrays, then saves these as `.npy` files for efficient storage and processing.\n",
    "\n",
    "3. **`show_EEG`**:\n",
    "   - Displays EEG signals graphically, providing a visual representation of the data across channels.\n",
    "\n",
    "---\n",
    "This script is designed to perform custom segmentation of EEG data from the CHB-MIT public dataset, which contains hours of continuous EEG recordings. The segmentation process extracts data into manageable 10-second windows, enabling efficient processing and analysis. The ultimate goal is to convert the raw EDF-format data into CSV files, reducing the file size (originally **42.6 GB of data from the Children’s Hospital of Boston-MIT Scalp EEG Dataset (Shoeb,2009) [Online] Accessed on 20 October 2024.**) and facilitating easier handling during analysis.\n",
    "\n",
    "---\n",
    "\n",
    "### Key Steps:\n",
    "1. **Library Imports**:\n",
    "   - Import the `mne` library for handling EDF files and `pandas` for data manipulation and export.\n",
    "\n",
    "2. **Reading EDF Files**:\n",
    "   - Utilise `mne.io.read_raw_edf` to read each EDF file within the dataset.\n",
    "   - Extract EEG signal data using the `get_data` method.\n",
    "\n",
    "3. **Data Conversion**:\n",
    "   - Transform the EEG signal data into a NumPy array using `numpy.vstack`.\n",
    "   - The vertical stack operation reshapes data into the format: _samples × features_, making it compatible for analysis.\n",
    "\n",
    "4. **Export to CSV**:\n",
    "   - Save the processed data into CSV files using `pandas.DataFrame.to_csv`. CSV format is smaller in size and allows easier processing across multiple platforms.\n",
    "\n",
    "---\n",
    "\n",
    "### Additional Information:\n",
    "This notebook acts as a preprocessing tool that simplifies the complex structure of continuous EEG data into structured samples. It enables researchers or engineers to:\n",
    "- Efficiently analyse smaller, well-defined EEG segments.\n",
    "- Perform further steps like machine learning model training or statistical analysis."
   ],
   "id": "edd833939a10607c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T07:33:34.781390Z",
     "start_time": "2025-02-10T07:33:34.771166Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define the raw data source directory for the CHB-MIT dataset.\n",
    "# The dataset contains 23 patients. Each patient's data is stored in a folder:\n",
    "# - Each folder is named with an integer identifier ranging from 0 to 24.\n",
    "# - Note: 22 patients have a single folder, and 1 patient (chb21) has two folders.\n",
    "\n",
    "path = r'data\\raw_data\\chb-mit-scalp-eeg-database-1.0.0'\n",
    "\n",
    "# Retrieve and sort the list of data folders based on their assigned numeri\n",
    "data_folders = sorted(glob.glob(os.path.join(path, '*[0-9]')))\n",
    "\n",
    "\n",
    "def file_id(folder):\n",
    "    \"\"\"\n",
    "    Extracts the last two characters of each folder's name, corresponding to its numeric identifier.\n",
    "\n",
    "    Parameters:\n",
    "        folder (list): List of folder paths.\n",
    "\n",
    "    Returns:\n",
    "        list: List of folder identifiers as strings.\n",
    "    \"\"\"\n",
    "    return [ name[-2:] for name in [file.rsplit('\\\\',2)[-1] for file in folder]]\n",
    "\n",
    "# Display the retrieved folder identifiers.\n",
    "\n",
    "print(\"Case ID: \")\n",
    "print(file_id(data_folders))"
   ],
   "id": "b797d0c19547718a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Case ID: \n",
      "['01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24']\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-09T15:29:34.574601Z",
     "start_time": "2025-02-09T15:29:34.542844Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# The seizure marking is included in the name of the EDF file, not in a separate file.\n",
    "# Split the data folders into training and testing sets.\n",
    "\n",
    "train_test_ratio = 0.8\n",
    "random.seed(80)\n",
    "\n",
    "# Randomly sample folders for the training set, then sort them.\n",
    "train_folders = sorted(random.sample(data_folders, round(len(data_folders) * train_test_ratio)))\n",
    "\n",
    "# Assign the remaining folders to the testing set and sort them.\n",
    "test_folders = sorted([ file for file in data_folders if file not in train_folders])\n",
    "\n",
    "# Display the IDs and counts of training and testing folders.\n",
    "print(f\"train_folders' IDs: {file_id(train_folders)}, contains {len(train_folders)} files\")\n",
    "print(f\"test_folders' IDs: {file_id(test_folders)}, contains {len(test_folders)} files\")\n"
   ],
   "id": "2bc6e28cdb2717b3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_folders' IDs: ['01', '02', '04', '07', '08', '09', '10', '12', '13', '14', '15', '16', '17', '18', '19', '20', '22', '23', '24'], contains 19 files\n",
      "test_folders' IDs: ['03', '05', '06', '11', '21'], contains 5 files\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-09T15:29:37.557633Z",
     "start_time": "2025-02-09T15:29:37.529995Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Retrieve all EDF files for training and testing sets.\n",
    "\n",
    "# Collect all EDF files from the training folders.\n",
    "train_files = [ file for folder in train_folders for file in glob.glob(folder+'/*.edf')]\n",
    "\n",
    "# Collect all EDF files from the testing folders.\n",
    "test_files = [ file for folder in test_folders for file in glob.glob(folder+'/*.edf')]\n",
    "\n",
    "# Display the counts of training and testing files.\n",
    "print(f\"Train_files contains {len(train_files)} files\")\n",
    "print(f\"Test_files contains {len(test_files)} files\")\n",
    "\n",
    "# Display a random example of a file from the training set.\n",
    "print(f\"Random example from train_files: {random.choice(train_files)}\")\n"
   ],
   "id": "c918f7ef2f9a282f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_files contains 523 files\n",
      "Test_files contains 163 files\n",
      "Random example from train_files: data\\raw_data\\chb-mit-scalp-eeg-database-1.0.0\\chb01\\chb01_16.edf\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Sampling a file at random",
   "id": "b4715598a870caae"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-16T09:19:44.294980Z",
     "start_time": "2025-01-16T09:19:42.340392Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# This code demonstrates reading neurophysiological data from an EDF file using the MNE library.\n",
    "\n",
    "# Load the first EDF file from the training set without preloading data into memory.\n",
    "sample_edf = mne.io.read_raw_edf(train_files[0], preload=False)\n",
    "sample_edf.info"
   ],
   "id": "569762c98a1f7205",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from C:\\Users\\mspla\\Documents\\repos\\py_basic_310_Au24\\seizurePy3.9\\data\\raw_data\\chb-mit-scalp-eeg-database-1.0.0\\chb01\\chb01_01.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mspla\\AppData\\Local\\Temp\\ipykernel_5836\\3700619184.py:4: RuntimeWarning: Channel names are not unique, found duplicates for: {'T8-P8'}. Applying running numbers for duplicates.\n",
      "  sample_edf = mne.io.read_raw_edf(train_files[0], preload=False)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Info | 8 non-empty values\n",
       " bads: []\n",
       " ch_names: FP1-F7, F7-T7, T7-P7, P7-O1, FP1-F3, F3-C3, C3-P3, P3-O1, ...\n",
       " chs: 23 EEG\n",
       " custom_ref_applied: False\n",
       " highpass: 0.0 Hz\n",
       " lowpass: 128.0 Hz\n",
       " meas_date: 2076-11-06 11:42:54 UTC\n",
       " nchan: 23\n",
       " projs: []\n",
       " sfreq: 256.0 Hz\n",
       " subject_info: 1 item (dict)\n",
       ">"
      ],
      "text/html": [
       "<script type=\"text/javascript\">\n",
       "    const toggleVisibility = (className) => {\n",
       "\n",
       "  const elements = document.querySelectorAll(`.${className}`)\n",
       "\n",
       "  elements.forEach(element => {\n",
       "    if (element.classList.contains('repr-section-header')) {\n",
       "      // Don't collapse the section header row.\n",
       "       return\n",
       "    }\n",
       "    if (element.classList.contains('repr-element-collapsed')) {\n",
       "      // Force a reflow to ensure the display change takes effect before removing the class\n",
       "      element.classList.remove('repr-element-collapsed')\n",
       "      element.offsetHeight // This forces the browser to recalculate layout\n",
       "      element.classList.remove('repr-element-faded')\n",
       "    } else {\n",
       "      // Start transition to hide the element\n",
       "      element.classList.add('repr-element-faded')\n",
       "      element.addEventListener('transitionend', handler = (e) => {\n",
       "        if (e.propertyName === 'opacity' && getComputedStyle(element).opacity === '0.2') {\n",
       "          element.classList.add('repr-element-collapsed')\n",
       "          element.removeEventListener('transitionend', handler)\n",
       "        }\n",
       "      });\n",
       "    }\n",
       "  });\n",
       "\n",
       "  // Take care of button (adjust caret)\n",
       "  const button = document.querySelectorAll(`.repr-section-header.${className} > th.repr-section-toggle-col > button`)[0]\n",
       "  button.classList.toggle('collapsed')\n",
       "\n",
       "  // Take care of the tooltip of the section header row\n",
       "  const sectionHeaderRow = document.querySelectorAll(`tr.repr-section-header.${className}`)[0]\n",
       "  sectionHeaderRow.classList.toggle('collapsed')\n",
       "  sectionHeaderRow.title = sectionHeaderRow.title === 'Hide section' ? 'Show section' : 'Hide section'\n",
       "}\n",
       "</script>\n",
       "\n",
       "<style type=\"text/css\">\n",
       "    table.repr.table.table-hover.table-striped.table-sm.table-responsive.small {\n",
       "  /* Don't make rows wider than they need to be. */\n",
       "  display: inline;\n",
       "}\n",
       "\n",
       "table > tbody > tr.repr-element > td {\n",
       "  /* Apply a tighter layout to the table cells. */\n",
       "  padding-top: 0.1rem;\n",
       "  padding-bottom: 0.1rem;\n",
       "  padding-right: 1rem;\n",
       "}\n",
       "\n",
       "table > tbody > tr > td.repr-section-toggle-col {\n",
       "  /* Remove background and border of the first cell in every row\n",
       "     (this row is only used for the collapse / uncollapse caret)\n",
       "\n",
       "     TODO: Need to find a good solution for VS Code that works in both\n",
       "           light and dark mode. */\n",
       "  border-color: transparent;\n",
       "  --bs-table-accent-bg: transparent;\n",
       "}\n",
       "\n",
       "tr.repr-section-header {\n",
       "  /* Remove stripes from section header rows */\n",
       "  background-color: transparent;\n",
       "  border-color: transparent;\n",
       "  --bs-table-striped-bg: transparent;\n",
       "  cursor: pointer;\n",
       "}\n",
       "\n",
       "tr.repr-section-header > th {\n",
       "  text-align: left !important;\n",
       "  vertical-align: middle;\n",
       "}\n",
       "\n",
       ".repr-element, tr.repr-element > td {\n",
       "  opacity: 1;\n",
       "  text-align: left !important;\n",
       "}\n",
       "\n",
       ".repr-element-faded {\n",
       "  transition: 0.3s ease;\n",
       "  opacity: 0.2;\n",
       "}\n",
       "\n",
       ".repr-element-collapsed {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "/* Collapse / uncollapse button and the caret it contains. */\n",
       ".repr-section-toggle-col button {\n",
       "  cursor: pointer;\n",
       "  width: 1rem;\n",
       "  background-color: transparent;\n",
       "  border-color: transparent;\n",
       "}\n",
       "\n",
       "span.collapse-uncollapse-caret {\n",
       "  width: 1rem;\n",
       "  height: 1rem;\n",
       "  display: block;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: left;\n",
       "  background-size: contain;\n",
       "}\n",
       "\n",
       "/* The collapse / uncollapse carets were copied from the free Font Awesome collection and adjusted. */\n",
       "\n",
       "/* Default to black carets for light mode */\n",
       ".repr-section-toggle-col > button.collapsed > span.collapse-uncollapse-caret {\n",
       "  background-image: url('data:image/svg+xml;charset=utf8,<svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 256 512\"><!--!Font Awesome Free 6.5.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free Copyright 2024 Fonticons, Inc.--><path fill=\"black\" d=\"M246.6 278.6c12.5-12.5 12.5-32.8 0-45.3l-128-128c-9.2-9.2-22.9-11.9-34.9-6.9s-19.8 16.6-19.8 29.6l0 256c0 12.9 7.8 24.6 19.8 29.6s25.7 2.2 34.9-6.9l128-128z\"/></svg>');\n",
       "}\n",
       "\n",
       ".repr-section-toggle-col\n",
       "  > button:not(.collapsed)\n",
       "  > span.collapse-uncollapse-caret {\n",
       "  background-image: url('data:image/svg+xml;charset=utf8,<svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 320 512\"><!--!Font Awesome Free 6.5.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free Copyright 2024 Fonticons, Inc.--><path fill=\"black\" d=\"M137.4 374.6c12.5 12.5 32.8 12.5 45.3 0l128-128c9.2-9.2 11.9-22.9 6.9-34.9s-16.6-19.8-29.6-19.8L32 192c-12.9 0-24.6 7.8-29.6 19.8s-2.2 25.7 6.9 34.9l128 128z\"/></svg>');\n",
       "}\n",
       "\n",
       "/* Use white carets for dark mode */\n",
       "@media (prefers-color-scheme: dark) {\n",
       "  .repr-section-toggle-col > button.collapsed > span.collapse-uncollapse-caret {\n",
       "    background-image: url('data:image/svg+xml;charset=utf8,<svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 256 512\"><!--!Font Awesome Free 6.5.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free Copyright 2024 Fonticons, Inc.--><path fill=\"white\" d=\"M246.6 278.6c12.5-12.5 12.5-32.8 0-45.3l-128-128c-9.2-9.2-22.9-11.9-34.9-6.9s-19.8 16.6-19.8 29.6l0 256c0 12.9 7.8 24.6 19.8 29.6s25.7 2.2 34.9-6.9l128-128z\"/></svg>');\n",
       "  }\n",
       "\n",
       "  .repr-section-toggle-col\n",
       "    > button:not(.collapsed)\n",
       "    > span.collapse-uncollapse-caret {\n",
       "    background-image: url('data:image/svg+xml;charset=utf8,<svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 320 512\"><!--!Font Awesome Free 6.5.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free Copyright 2024 Fonticons, Inc.--><path fill=\"white\" d=\"M137.4 374.6c12.5 12.5 32.8 12.5 45.3 0l128-128c9.2-9.2 11.9-22.9 6.9-34.9s-16.6-19.8-29.6-19.8L32 192c-12.9 0-24.6 7.8-29.6 19.8s-2.2 25.7 6.9 34.9l128 128z\"/></svg>');\n",
       "  }\n",
       "}\n",
       "\n",
       ".channel-names-btn {\n",
       "  padding: 0;\n",
       "  border: none;\n",
       "  background: none;\n",
       "  text-decoration: underline;\n",
       "  text-decoration-style: dashed;\n",
       "  cursor: pointer;\n",
       "  color: #0d6efd;\n",
       "}\n",
       "\n",
       ".channel-names-btn:hover {\n",
       "  color: #0a58ca;\n",
       "}\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "<table class=\"repr table table-hover table-striped table-sm table-responsive small\">\n",
       "    \n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "<tr class=\"repr-section-header general-3e41dd14-2ae6-4369-ae81-9b8e49b01114\"  title=\"Hide section\" \n",
       "    onclick=\"toggleVisibility('general-3e41dd14-2ae6-4369-ae81-9b8e49b01114')\">\n",
       "    <th class=\"repr-section-toggle-col\">\n",
       "        <button>\n",
       "            \n",
       "            <span class=\"collapse-uncollapse-caret\"></span>\n",
       "        </button>\n",
       "    </th>\n",
       "    <th colspan=\"2\">\n",
       "        <strong>General</strong>\n",
       "    </th>\n",
       "</tr>\n",
       "\n",
       "<tr class=\"repr-element general-3e41dd14-2ae6-4369-ae81-9b8e49b01114 \">\n",
       "    <td class=\"repr-section-toggle-col\"></td>\n",
       "    <td>MNE object type</td>\n",
       "    <td>Info</td>\n",
       "</tr>\n",
       "<tr class=\"repr-element general-3e41dd14-2ae6-4369-ae81-9b8e49b01114 \">\n",
       "    <td class=\"repr-section-toggle-col\"></td>\n",
       "    <td>Measurement date</td>\n",
       "    \n",
       "    <td>2076-11-06 at 11:42:54 UTC</td>\n",
       "    \n",
       "</tr>\n",
       "<tr class=\"repr-element general-3e41dd14-2ae6-4369-ae81-9b8e49b01114 \">\n",
       "    <td class=\"repr-section-toggle-col\"></td>\n",
       "    <td>Participant</td>\n",
       "    \n",
       "    \n",
       "    <td>Surrogate</td>\n",
       "    \n",
       "    \n",
       "</tr>\n",
       "<tr class=\"repr-element general-3e41dd14-2ae6-4369-ae81-9b8e49b01114 \">\n",
       "    <td class=\"repr-section-toggle-col\"></td>\n",
       "    <td>Experimenter</td>\n",
       "    \n",
       "    <td>Unknown</td>\n",
       "    \n",
       "</tr>\n",
       "    \n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "<tr class=\"repr-section-header acquisition-6d64b5d3-e0f7-4dfd-ac25-6481159d00d7\" \n",
       "    title=\"Hide section\"  onclick=\"toggleVisibility('acquisition-6d64b5d3-e0f7-4dfd-ac25-6481159d00d7')\">\n",
       "    <th class=\"repr-section-toggle-col\">\n",
       "        <button>\n",
       "            \n",
       "            <span class=\"collapse-uncollapse-caret\"></span>\n",
       "        </button>\n",
       "    </th>\n",
       "    <th colspan=\"2\">\n",
       "        <strong>Acquisition</strong>\n",
       "    </th>\n",
       "</tr>\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "<tr class=\"repr-element acquisition-6d64b5d3-e0f7-4dfd-ac25-6481159d00d7 \">\n",
       "    <td class=\"repr-section-toggle-col\"></td>\n",
       "    <td>Sampling frequency</td>\n",
       "    <td>256.00 Hz</td>\n",
       "</tr>\n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "<tr class=\"repr-section-header channels-f97b11fd-c274-4c23-b860-49cc0c2771d7\"  title=\"Hide section\" \n",
       "    onclick=\"toggleVisibility('channels-f97b11fd-c274-4c23-b860-49cc0c2771d7')\">\n",
       "    <th class=\"repr-section-toggle-col\">\n",
       "        <button>\n",
       "            \n",
       "            <span class=\"collapse-uncollapse-caret\"></span>\n",
       "        </button>\n",
       "    </th>\n",
       "    <th colspan=\"2\">\n",
       "        <strong>Channels</strong>\n",
       "    </th>\n",
       "</tr>\n",
       "\n",
       "\n",
       "<tr class=\"repr-element channels-f97b11fd-c274-4c23-b860-49cc0c2771d7 \">\n",
       "    <td class=\"repr-section-toggle-col\"></td>\n",
       "    <td>EEG</td>\n",
       "    <td>\n",
       "        <button class=\"channel-names-btn\" onclick=\"alert('Good EEG:\\n\\nFP1-F7, F7-T7, T7-P7, P7-O1, FP1-F3, F3-C3, C3-P3, P3-O1, FP2-F4, F4-C4, C4-P4, P4-O2, FP2-F8, F8-T8, T8-P8-0, P8-O2, FZ-CZ, CZ-PZ, P7-T7, T7-FT9, FT9-FT10, FT10-T8, T8-P8-1')\" title=\"(Click to open in popup)&#13;&#13;FP1-F7, F7-T7, T7-P7, P7-O1, FP1-F3, F3-C3, C3-P3, P3-O1, FP2-F4, F4-C4, C4-P4, P4-O2, FP2-F8, F8-T8, T8-P8-0, P8-O2, FZ-CZ, CZ-PZ, P7-T7, T7-FT9, FT9-FT10, FT10-T8, T8-P8-1\">\n",
       "            23\n",
       "        </button>\n",
       "\n",
       "        \n",
       "    </td>\n",
       "</tr>\n",
       "\n",
       "\n",
       "<tr class=\"repr-element channels-f97b11fd-c274-4c23-b860-49cc0c2771d7 \">\n",
       "    <td class=\"repr-section-toggle-col\"></td>\n",
       "    <td>Head & sensor digitization</td>\n",
       "    \n",
       "    <td>Not available</td>\n",
       "    \n",
       "</tr>\n",
       "    \n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "<tr class=\"repr-section-header filters-547e1f69-07ac-4be6-9266-44b973ca35b5\"  title=\"Hide section\" \n",
       "    onclick=\"toggleVisibility('filters-547e1f69-07ac-4be6-9266-44b973ca35b5')\">\n",
       "    <th class=\"repr-section-toggle-col\">\n",
       "        <button>\n",
       "            \n",
       "            <span class=\"collapse-uncollapse-caret\"></span>\n",
       "        </button>\n",
       "    </th>\n",
       "    <th colspan=\"2\">\n",
       "        <strong>Filters</strong>\n",
       "    </th>\n",
       "</tr>\n",
       "\n",
       "<tr class=\"repr-element filters-547e1f69-07ac-4be6-9266-44b973ca35b5 \">\n",
       "    <td class=\"repr-section-toggle-col\"></td>\n",
       "    <td>Highpass</td>\n",
       "    <td>0.00 Hz</td>\n",
       "</tr>\n",
       "\n",
       "\n",
       "<tr class=\"repr-element filters-547e1f69-07ac-4be6-9266-44b973ca35b5 \">\n",
       "    <td class=\"repr-section-toggle-col\"></td>\n",
       "    <td>Lowpass</td>\n",
       "    <td>128.00 Hz</td>\n",
       "</tr>\n",
       "\n",
       "\n",
       "</table>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-01T04:27:08.777175Z",
     "start_time": "2025-01-01T04:27:07.183483Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Identify the montage used for surface electrodes.\n",
    "# The montage refers to the naming convention used to identify each surface scalp electrode.\n",
    "\n",
    "# Display a description of the EDF file, including details about the electrode placement and montage.\n",
    "sample_edf.describe()"
   ],
   "id": "73bf9703f3169dc0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<RawEDF | chb01_01.edf, 23 x 921600 (3600.0 s), ~27 kB, data not loaded>\n",
      "ch  name      type  unit        min         Q1     median         Q3        max\n",
      " 0  FP1-F7    EEG   µV      -807.03     -24.03      -1.37      19.73    1037.95\n",
      " 1  F7-T7     EEG   µV      -726.54     -17.00       0.20      17.00     549.55\n",
      " 2  T7-P7     EEG   µV      -544.47     -13.48       0.20      14.26     588.62\n",
      " 3  P7-O1     EEG   µV      -449.52     -10.74       0.59      11.53     206.11\n",
      " 4  FP1-F3    EEG   µV      -882.44     -26.37      -0.98      22.86     792.19\n",
      " 5  F3-C3     EEG   µV      -431.94     -14.65       0.20      15.04     402.25\n",
      " 6  C3-P3     EEG   µV      -417.09     -10.35       0.20      10.74     536.65\n",
      " 7  P3-O1     EEG   µV      -201.03     -13.48       0.20      14.26     229.94\n",
      " 8  FP2-F4    EEG   µV      -563.61     -24.03      -0.98      20.51     700.76\n",
      " 9  F4-C4     EEG   µV      -262.76     -13.48       0.20      13.48     235.41\n",
      "10  C4-P4     EEG   µV      -284.64     -10.35       0.20      11.14     400.29\n",
      "11  P4-O2     EEG   µV      -435.07     -13.48       0.20      14.26     694.11\n",
      "12  FP2-F8    EEG   µV      -654.65     -22.08      -0.98      18.17     963.32\n",
      "13  F8-T8     EEG   µV      -489.77     -17.78      -0.59      17.39     419.44\n",
      "14  T8-P8-0   EEG   µV      -626.91     -13.87       0.59      15.04     364.74\n",
      "15  P8-O2     EEG   µV      -474.92     -14.65       0.59      15.82     620.66\n",
      "16  FZ-CZ     EEG   µV      -199.46     -13.09       0.20      13.09     149.84\n",
      "17  CZ-PZ     EEG   µV      -195.16     -12.70       0.20      13.09     248.69\n",
      "18  P7-T7     EEG   µV      -588.23     -13.87       0.20      13.87     544.86\n",
      "19  T7-FT9    EEG   µV      -548.38     -13.48       0.98      14.26     764.05\n",
      "20  FT9-FT10  EEG   µV      -606.59     -20.51      -0.20      21.68     630.04\n",
      "21  FT10-T8   EEG   µV      -445.62     -12.70      -0.20      12.70     470.62\n",
      "22  T8-P8-1   EEG   µV      -626.91     -13.87       0.59      15.04     364.74\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Surface electrodes",
   "id": "af5f678a76f1d71b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-01T03:23:10.553436600Z",
     "start_time": "2025-01-01T03:21:25.805167Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 9,
   "source": [
    "channel_labels = ['FP1-F7', 'F7-T7', 'T7-P7', 'P7-O1', 'FP1-F3', 'F3-C3', 'C3-P3','P3-O1',\n",
    "                  'FP2-F4', 'F4-C4', 'C4-P4', 'P4-O2', 'FP2-F8', 'F8-T8', 'T8-P8', 'P8-O2',\n",
    "                  'FZ-CZ', 'CZ-PZ', 'P7-T7', 'T7-FT9', 'FT9-FT10', 'FT10-T8', 'T8-P8-1']"
   ],
   "id": "46aaabedfd01431b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "### The International 10-20 Electrode Placement System\n",
    "\n",
    "The **10-20 International System** is a globally standardised method for positioning scalp electrodes in EEG recordings. It ensures uniformity and reproducibility in electrode placement, allowing consistent measurement of brain signal amplitudes across studies.\n",
    "\n",
    "#### Electrode Configuration:\n",
    "- **Older Systems**: Utilise 18 pairs of channels for brain signal detection.\n",
    "- **Modern Systems**: May include 23, 24, or even 26 pairs of channels, depending on the complexity and requirements of the analysis.\n",
    "\n",
    "#### Project Implementation:\n",
    "For this project, we are using **23 channels** to extract and analyse EEG signals effectively.\n",
    "\n",
    "#### EEG Montage:\n",
    "- EEG files represent a montage of amplitudes detected across multiple channels.\n",
    "- Each channel records the electrical potential difference between two specific scalp electrodes.\n",
    "- The montage is arranged systematically:\n",
    "  - **From left to right** across the scalp.\n",
    "  - **From the front (frontal region) to the back (occipital region)**.\n",
    "\n",
    "#### Electrode Labels:\n",
    "The following labels correspond to the channels used in this project:\n",
    "\n",
    "```python\n",
    "['FP1-F7', 'F7-T7', 'T7-P7', 'P7-O1', 'FP1-F3', 'F3-C3', 'C3-P3', 'P3-O1',\n",
    " 'FP2-F4', 'F4-C4', 'C4-P4', 'P4-O2', 'FP2-F8', 'F8-T8', 'T8-P8', 'P8-O2',\n",
    " 'FZ-CZ', 'CZ-PZ', 'P7-T7', 'T7-FT9', 'FT9-FT10', 'FT10-T8', 'T8-P8-1']\n",
    "```\n",
    "\n",
    "These labels follow the 10-20 International System, ensuring optimal coverage of the scalp for reliable signal acquisition. The systematic arrangement enables analysis of neural activity across hemispheres and regions of interest.\n",
    "\n",
    "---"
   ],
   "id": "136174c9f9ea2c74"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Signal Extraction\n",
    "\n",
    "Codes extensively modified from work by [Mashahiro Goton](https://www.kaggle.com/code/hemangjindal/chb-mit-eeg-dataset-my-notebook#CHB-MIT-eeg-dataset-seizure-detection-demo). \\[Online] [Accesssed on 20 October 2024].\n",
    "\n",
    "EDfToNpy class contains:\n",
    "1. read_efd - read edf formatted seizure file. Identify parameters for creating numpy arrays. Ensure correct channels and calculate samples of seizure and non seizure files.\n",
    "2. extract_edf - create appropriate numpy arrays using arguments obtained from read_edf method. Copy data and labels to numpy array, then save to file as npy format.\n",
    "3. show_EEG - display EEG\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "#### Signal Extraction\n",
    "\n",
    "The code presented in this notebook is extensively modified from work by [Mashahiro Goton](https://www.kaggle.com/code/hemangjindal/chb-mit-eeg-dataset-my-notebook#CHB-MIT-eeg-dataset-seizure-detection-demo).\n",
    "**[Online] Accessed on 20 October 2024.**\n",
    "\n",
    "#### Overview of the `EdfToNpy` Class\n",
    "\n",
    "The `EdfToNpy` class provides functionalities for processing EEG data from EDF files, specifically from the CHB-MIT dataset. It includes the following methods:\n",
    "\n",
    "1. **`read_edf`**:\n",
    "   - Reads EDF-formatted seizure files.\n",
    "   - Identifies parameters for creating NumPy arrays, ensuring correct channel mapping.\n",
    "   - Calculates samples for both seizure and non-seizure files.\n",
    "\n",
    "2. **`extract_edf`**:\n",
    "   - Creates NumPy arrays using the parameters obtained from the `read_edf` method.\n",
    "   - Copies EEG data and corresponding labels to NumPy arrays, then saves these as `.npy` files for efficient storage and processing.\n",
    "\n",
    "3. **`show_EEG`**:\n",
    "   - Displays EEG signals graphically, providing a visual representation of the data across channels.\n",
    "\n",
    "---"
   ],
   "id": "85cc78864d88805b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T07:33:46.696571Z",
     "start_time": "2025-02-10T07:33:46.680663Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class EdfToNpy:\n",
    "    # Constants\n",
    "    WINDOW_TIME = 10  # segment size in second\n",
    "    STEP_TIME = 5     # Step size in second\n",
    "    SEIZURE_PROPORTION = 0.01    # proportion of seizure\n",
    "    TO_MICROVOLTS = 1e6\n",
    "    channel_labels = ['FP1-F7', 'F7-T7', 'T7-P7', 'P7-O1', 'FP1-F3', 'F3-C3', 'C3-P3', 'P3-O1',\n",
    "                      'FP2-F4', 'F4-C4', 'C4-P4', 'P4-O2', 'FP2-F8', 'F8-T8', 'T8-P8', 'P8-O2',\n",
    "                      'FZ-CZ', 'CZ-PZ', 'P7-T7', 'T7-FT9', 'FT9-FT10', 'FT10-T8', 'T8-P8-1']\n",
    "\n",
    "    def __init__(self, folder, save_to):\n",
    "        self.save_to = save_to\n",
    "        self.folder = folder\n",
    "\n",
    "    # Read edf formatted file\n",
    "    def read_edf(self):\n",
    "        count = 0  # initialize the count variable\n",
    "        window_size = 0  # initialize the window_size variable\n",
    "\n",
    "        for file in self.folder:\n",
    "            edf_data = mne.io.read_raw_edf(file, preload=False)\n",
    "            edf_labels = edf_data.ch_names\n",
    "\n",
    "            if sum([any([0 if re.match(c, l) is None else 1 for l in edf_labels]) for c in EdfToNpy.channel_labels]) == len(EdfToNpy.channel_labels):\n",
    "                sampling_freq = int(1 / (edf_data.times[1] - edf_data.times[0]))\n",
    "                window_size = sampling_freq * EdfToNpy.WINDOW_TIME\n",
    "                window_stride = sampling_freq * EdfToNpy.STEP_TIME\n",
    "\n",
    "                has_seizure = np.zeros((edf_data.n_times,))\n",
    "                if os.path.exists(file + '.seizures'):\n",
    "                    has_annotation = wfdb.rdann(file, 'seizures')\n",
    "                    for idx in range(int(has_annotation.sample.size / 2)):\n",
    "                        has_seizure[has_annotation.sample[idx * 2]:has_annotation.sample[idx * 2 + 1]] = 1\n",
    "\n",
    "                has_seizure_idx = np.array([has_seizure[idx * window_stride:idx * window_stride + window_size].sum() / window_size for idx in range((edf_data.n_times - window_size) // window_stride)])\n",
    "\n",
    "                noseizure_n_size = round(EdfToNpy.SEIZURE_PROPORTION * np.where(has_seizure_idx == 0)[0].size)\n",
    "                seizure_n_size = np.where(has_seizure_idx > 0)[0].size\n",
    "                count = count + noseizure_n_size + seizure_n_size  # increment count to tally total samples\n",
    "\n",
    "            edf_data.close()\n",
    "\n",
    "        return count, len(EdfToNpy.channel_labels), window_size\n",
    "\n",
    "    # Segment data into 10-second window and save data to numpy data file. Also save seizure annotation to numpy label file.\n",
    "    def extract_edf(self, n_samples, n_channel_labels, window_size):\n",
    "        signals_np = np.zeros((n_samples, n_channel_labels, window_size), dtype=np.float32)\n",
    "        labels_np = np.zeros(n_samples, dtype=np.int32)\n",
    "        count = 0  # initialize the count variable\n",
    "\n",
    "        for number, file in enumerate(self.folder):\n",
    "            edf_data = mne.io.read_raw_edf(file, preload=False)\n",
    "\n",
    "            n_label_match = sum([any([0 if re.match(ch, ch_name) is None else 1 for ch_name in edf_data.ch_names]) for ch in EdfToNpy.channel_labels])\n",
    "            if n_label_match == len(EdfToNpy.channel_labels):\n",
    "                dict_ch_name = {sorted([ch_name for ch_name in edf_data.ch_names if re.match(ch, ch_name) is not None])[0]: ch for ch in EdfToNpy.channel_labels}\n",
    "                edf_data.rename_channels(dict_ch_name)\n",
    "\n",
    "                has_seizure = np.zeros((edf_data.n_times,))\n",
    "                signals_ = edf_data.get_data(picks=EdfToNpy.channel_labels) * EdfToNpy.TO_MICROVOLTS\n",
    "\n",
    "                if os.path.exists(file + '.seizures'):\n",
    "                    has_annotation = wfdb.rdann(file, 'seizures')\n",
    "                    for idx in range(int(has_annotation.sample.size / 2)):\n",
    "                        has_seizure[has_annotation.sample[idx * 2]:has_annotation.sample[idx * 2 + 1]] = 1\n",
    "\n",
    "                sampling_freq = int(1 / (edf_data.times[1] - edf_data.times[0]))\n",
    "                window_size = sampling_freq * EdfToNpy.WINDOW_TIME\n",
    "                window_stride = sampling_freq * EdfToNpy.STEP_TIME\n",
    "                has_seizure_idx = np.array([has_seizure[idx * window_stride:idx * window_stride + window_size].sum() / window_size for idx in range((edf_data.n_times - window_size) // window_stride)])\n",
    "\n",
    "                noseizure_n_size = round(EdfToNpy.SEIZURE_PROPORTION * np.where(has_seizure_idx == 0)[0].size)\n",
    "                seizure_n_size = np.where(has_seizure_idx > 0)[0].size\n",
    "\n",
    "                # Non-seizure data\n",
    "                temp_negative = random.sample(list(np.where(has_seizure_idx == 0)[0]), noseizure_n_size)  # sample non-seizure data correctly\n",
    "                for value in temp_negative:\n",
    "                    start_index = value * window_stride\n",
    "                    stop_index = value * window_stride + window_size\n",
    "                    signals_np[count, :, :] = signals_[:, start_index:stop_index]\n",
    "                    labels_np[count] = 0\n",
    "                    count = count + 1\n",
    "\n",
    "                # Seizure data\n",
    "                temp_positive = list(np.where(has_seizure_idx > 0)[0])  # sample seizure data correctly\n",
    "                for value in temp_positive:\n",
    "                    start_index = value * window_stride\n",
    "                    stop_index = value * window_stride + window_size\n",
    "                    signals_np[count, :, :] = signals_[:, start_index:stop_index]\n",
    "                    labels_np[count] = 1\n",
    "                    count = count + 1\n",
    "            else:\n",
    "                print(f\"Unable to read {file}\")\n",
    "\n",
    "            edf_data.close()\n",
    "\n",
    "        np.save(self.save_to + '_signals', signals_np)\n",
    "        np.save(self.save_to + '_labels', labels_np)\n",
    "\n",
    "    def show_eeg(self, signals):\n",
    "        vertical_width = 250\n",
    "        fs = 256\n",
    "\n",
    "        fig, ax = plt.subplots()\n",
    "        for i in range(signals.shape[0]):\n",
    "            ax.plot(np.arange(signals.shape[-1]) / fs, signals[i, :] + i * vertical_width, linewidth=0.5, color='tab:blue')\n",
    "            ax.annotate(EdfToNpy.channel_labels[i], xy=(0, i * vertical_width))\n",
    "        ax.invert_yaxis()\n",
    "        plt.show()"
   ],
   "id": "96dfc893926d4748",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "#### Construct Training Dataset with Extended 10-second Context Windows\n",
    "\n",
    "This section outlines the process of generating a training dataset by dividing EEG data into 10-second segments. The primary objective is to enhance prediction accuracy by providing a larger context window, enabling the incorporation of more comprehensive information for processing and analysis.\n",
    "\n",
    "---"
   ],
   "id": "1e33234716d4d508"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Approximately 5-6 minutes to execute this cell.\n",
    "# Extract EEG data into a training NumPy file.\n",
    "\n",
    "# Step 1: Instantiate the `EdfToNpy` class with training files and specify the output filen\n",
    "train_npy =  EdfToNpy(train_files, 'train_10sec')\n",
    "\n",
    "# Step 2: Process the training samples to retrieve required parameters.\n",
    "sample_length, channel_length, window_length = train_npy.read_edf()\n",
    "\n",
    "# Step 3: Use the extracted parameters to create NumPy arrays of the data.\n",
    "train_npy.extract_edf(sample_length, channel_length, window_length)\n",
    "\n",
    "# Note: The output of this cell is extensive and has been omitted for brevity."
   ],
   "id": "e70d06a18215e13e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "### Generate Testing Dataset with 10-Second Samples\n",
    "\n",
    "This section is dedicated to creating the testing dataset by segmenting EEG recordings into uniform 10-second windows. This ensures consistency and facilitates effective testing and validation of the data.\n",
    "\n",
    "---\n"
   ],
   "id": "eae223430e340bcf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Approximately 1-2 minutes to execute this cell.\n",
    "# Extract the remaining portion of EEG data into a testing NumPy file.\n",
    "\n",
    "# Step 1: Instantiate the `EdfToNpy` class with testing files and specify the output filename.\n",
    "test_npy = EdfToNpy(test_files, 'test_10sec')\n",
    "\n",
    "# Step 2: Process the testing samples to retrieve required parameters.\n",
    "sample_length, channel_length, window_length = test_npy.read_edf()\n",
    "\n",
    "# Step 3: Use the extracted parameters to create NumPy arrays of the testing data.\n",
    "test_npy.extract_edf(sample_length, channel_length, window_length)\n",
    "\n",
    "# Note: The output of this cell is extensive and has been omitted for brevity."
   ],
   "id": "76fc334939722bab",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "5cb348539ae0ff76",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "raw",
   "source": "",
   "id": "e1fe01556f81fab4",
   "outputs": null,
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "### First Iteration: EEG Data Segmentation\n",
    "\n",
    "In this initial attempt, we successfully implemented the functionality to read and convert raw EEG data in the EDF format into the NumPy format during the prototyping phase.\n",
    "\n",
    "The `EdfToNpy` class was developed to encapsulate all methods necessary for this process.\n",
    "\n",
    "Key achievements during this iteration include:\n",
    "- **Data Segmentation**: The raw EEG data was divided into manageable 10-second windows, forming the basis for each sample.\n",
    "- **Foundation for Further Development**: This iteration establishes the groundwork for efficient data handling and further improvements in context window segmentation length in subsequent iterations.\n",
    "\n",
    "---"
   ],
   "id": "65e09e005adf1f30"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T07:23:53.154044Z",
     "start_time": "2025-02-10T07:23:53.126708Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Verify that the NumPy label files for training and testing datasets are readable.\n",
    "\n",
    "# Training Data\n",
    "path_signal = 'train_10sec_signals.npy'\n",
    "path_label = 'train_10sec_labels.npy'\n",
    "\n",
    "# Check if the training label file exists and load its contents.\n",
    "if os.path.exists(path_label):\n",
    "    train_labels = np.load(path_label)\n",
    "    unique, count = np.unique(train_labels, return_counts=True)\n",
    "    print(f\"Train labels {unique} contain {count}\")\n",
    "\n",
    "# Testing  data\n",
    "path_signal = 'test_10sec_signals.npy'\n",
    "path_label = 'test_10sec_labels.npy'\n",
    "\n",
    "# Check if the testing label file exists and load its contents.\n",
    "if os.path.exists(path_label):\n",
    "    test_labels = np.load(path_label)\n",
    "    unique, count = np.unique(test_labels, return_counts=True)\n",
    "    print(f\"Test labels {unique} contains {count}\")"
   ],
   "id": "a27613cae92a2c7d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train labels [0 1] contain [9190  119]\n",
      "Test labels [0 1] contains [2307  186]\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "### Problems with Initial Segmentation\n",
    "\n",
    "The intial train-test split was performed based on **folders** or **case numbers**. This introduced several issues:\n",
    "- **Variability in Seizure Types**: Each case may exhibit a different seizure type. Since seizure types have distinct signal signatures, the segmentation approach likely resulted in training and testing sets with non-overlapping seizure patterns.\n",
    "- **Bias in Training Data**: The training samples presented to the classifier do not comprehensively represent all seizure types present in the full CHB-MIT dataset. This limits the model's ability to generalise across different seizure patterns.\n",
    "\n",
    "### Solution to Address the Problem\n",
    "\n",
    "> To correct this initial oversight, the entire CHB-MIT dataset has been re-segmented into uniform **10-second window samples**.\n",
    "> The segmented data is then converted into a **single NumPy signal file** and a **corresponding NumPy label file**, ensuring that all seizure types are included and better represented across the dataset. The `edfToNpy` class and subsequent segmentations uses corrected codes.\n",
    "\n",
    "---"
   ],
   "id": "96555c71e5719659"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T07:33:52.858322Z",
     "start_time": "2025-02-10T07:33:52.842447Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Verify that NumPy files are readable.\n",
    "# Retrieve all EDF files contained within the parent folder: \"data_folders\".\n",
    "\n",
    "# Collect all EDF files from the specified folders.\n",
    "all_edf = [ file for folder in data_folders for file in glob.glob(folder + '/*.edf')]\n",
    "\n",
    "# Display the total number of EDF files retrieved.\n",
    "\n",
    "print(f\"Total number of files is {len(all_edf)}\")"
   ],
   "id": "c438e12afeeac0ab",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of files is 686\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Estimated execution time: approximately 8-9 minutes for this cell.\n",
    "\n",
    "# Step 1: Instantiate the `EdfToNpy` class with all EDF files and specify the output prefix ('10sec').\n",
    "\n",
    "data_npy = EdfToNpy(all_edf, '10sec')\n",
    "\n",
    "# Step 2: Process the EDF files to retrieve the parameters required for segmentation.\n",
    "# This step ensures that the EEG signals are properly segmented into 10-second samples.\n",
    "sample_length, channel_length, window_length = data_npy.read_edf()\n",
    "\n",
    "# Step 3: Use the extracted parameters to convert the data into NumPy arrays.\n",
    "# Export the following files:\n",
    "# - \"10sec_signals.npy\": Contains segmented EEG signals.\n",
    "# - \"10sec_labels.npy\": Contains corresponding labels (1 for seizure, 0 for non-seizure).\n",
    "\n",
    "data_npy.extract_edf(sample_length, channel_length, window_length)"
   ],
   "id": "a128507273215948",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "####  Verify `10sec_labels.npy`",
   "id": "57a947b0ab37ed25"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T07:53:34.322962Z",
     "start_time": "2025-02-10T07:53:33.595347Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Verify that the NumPy files for signals and labels are readable.\n",
    "\n",
    "# Define paths for the signal and label files.\n",
    "path_signal = '10sec_signals.npy'\n",
    "path_label = '10sec_labels.npy'\n",
    "\n",
    "\n",
    "# Check if both the signal and label files exist before loading them.\n",
    "if os.path.exists(path_signal) and os.path.exists(path_label):\n",
    "    # Load the NumPy files containing the signals and labels.\n",
    "    full_data = np.load(path_signal)\n",
    "    full_labels = np.load(path_label)\n",
    "\n",
    "    # Retrieve unique labels and their respective counts.\n",
    "\n",
    "    unique, count = np.unique(full_labels, return_counts=True)\n",
    "\n",
    "    # Display the label distribution and the shapes of the data.\n",
    "\n",
    "    print(f\"Labels contain {count[0]} non-seizure samples and {count[1]} seizure samples\")\n",
    "    print(f\"Data shape is {full_data.shape}\")\n",
    "    print(f\"Labels' shape is {full_labels.shape}\")\n"
   ],
   "id": "9381ce7067d9fbd4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels contain 6744 non-seizure samples and 2606 seizure samples\n",
      "Data shape is (9350, 23, 2560)\n",
      "Labels' shape is (9350,)\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Bibligraphy\n",
    "\n",
    "Goton, M. (n.d.). *CHB-MIT EEG Dataset Seizure Detection Demo*. Available at: [https://www.kaggle.com/code/hemangjindal/chb-mit-eeg-dataset-my-notebook#CHB-MIT-eeg-dataset-seizure-detection-demo](https://www.kaggle.com/code/hemangjindal/chb-mit-eeg-dataset-my-notebook#CHB-MIT-eeg-dataset-seizure-detection-demo) [Accessed 20 October 2024].\n",
    "\n",
    "\n",
    "Shoeb, A. (2009). *CHB-MIT Scalp EEG Database*. Available at: [https://physionet.org/content/chbmit/1.0.0/](https://physionet.org/content/chbmit/1.0.0/) [Accessed 20 October 2024].\n",
    "\n",
    "\n"
   ],
   "id": "20f42d8ccf0d5ff6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "7c1aef8abef019c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### END",
   "id": "25723fef96db754a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
