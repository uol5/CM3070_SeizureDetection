{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Raw data are 42.6 GB in Edf format. Convert to csv for smaller size, and easier processing.\n",
    "\n",
    "1. Import mne and pandas library.\n",
    "2. mne.io.read_raw_edf to read each Edf file.\n",
    "3. mne.io.read_raw_edf.get_data to retrive read data.\n",
    "4. convert to numpy using  numpy.vstack. Vertical stack converts dimensions into shape of samples x features.\n",
    "5. save as csv using pandas.DataFrame.to_csv"
   ],
   "id": "edd833939a10607c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-09T14:44:22.519475Z",
     "start_time": "2025-02-09T14:44:21.928377Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import mne # reads edf format\n",
    "import glob\n",
    "import random\n",
    "import re\n",
    "import wfdb # waveform database library wfdb.rdann reads annotation of physiology annotated data in ECG, EEG etc\n"
   ],
   "id": "9e3119ec8ee92a61",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "raw",
   "source": [
    "raw_data = \"raw_CHB-Mit\"\n",
    "each case has filename ending with digit from chb01 - chb24"
   ],
   "id": "101877bfd0bfca0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-09T14:44:26.173016Z",
     "start_time": "2025-02-09T14:44:26.160774Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Each folder is assigned an integer from 0 to 24. There are 23 patients. 22 have a single folder, and 1 has two folders.\n",
    "# Retrieve assigned folder number from file\n",
    "\n",
    "path = r'data\\raw_data\\chb-mit-scalp-eeg-database-1.0.0'\n",
    "data_folders = sorted(glob.glob(os.path.join(path, '*[0-9]')))\n",
    "\n",
    "def file_id(folder):\n",
    "    return [ name[-2:] for name in [file.rsplit('\\\\',2)[-1] for file in folder]]\n",
    "print(\"Case ID: \")\n",
    "print(file_id(data_folders))"
   ],
   "id": "b797d0c19547718a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Case ID: \n",
      "['01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24']\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-16T09:19:38.090564Z",
     "start_time": "2025-01-16T09:19:38.076733Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# seizure  marking is in name of edf file, not a separate file\n",
    "# split files for training and testing\n",
    "train_test_ratio = 0.8\n",
    "random.seed(80)\n",
    "train_folders = sorted(random.sample(data_folders, round(len(data_folders) * train_test_ratio)))\n",
    "test_folders = sorted([ file for file in data_folders if file not in train_folders])\n",
    "print(f\"train_folders' IDs: {file_id(train_folders)}, contains {len(train_folders)} files\")\n",
    "print(f\"test_folders' IDs: {file_id(test_folders)}, contains {len(test_folders)} files\")\n"
   ],
   "id": "2bc6e28cdb2717b3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_folders' IDs: ['01', '02', '04', '07', '08', '09', '10', '12', '13', '14', '15', '16', '17', '18', '19', '20', '22', '23', '24'], contains 19 files\n",
      "test_folders' IDs: ['03', '05', '06', '11', '21'], contains 5 files\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-16T09:19:40.025783Z",
     "start_time": "2025-01-16T09:19:40.007920Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Retrieve edf files\n",
    "\n",
    "train_files = [ file for folder in train_folders for file in glob.glob(folder+'/*.edf')]\n",
    "test_files = [ file for folder in test_folders for file in glob.glob(folder+'/*.edf')]\n",
    "\n",
    "print(f\"Train_files contains {len(train_files)} files\")\n",
    "print(f\"Test_files contains {len(test_files)} files\")\n",
    "print(f\"Random example from train_files: {random.choice(train_files)}\")\n"
   ],
   "id": "c918f7ef2f9a282f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_files contains 523 files\n",
      "Test_files contains 163 files\n",
      "Random example from train_files: data\\raw_data\\chb-mit-scalp-eeg-database-1.0.0\\chb01\\chb01_16.edf\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "In raw files, some files are duplicated. Some files have duplicated name.",
   "id": "cd21563f206e8d71"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-01T03:23:10.543698Z",
     "start_time": "2025-01-01T03:21:20.318806Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "fea9eb8534264662",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-16T09:19:44.294980Z",
     "start_time": "2025-01-16T09:19:42.340392Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# MEG and EEG library (mne) reads neurophysiological data\n",
    "# dir(sample_edf)  # shows all attributes and methods\n",
    "\n",
    "sample_edf = mne.io.read_raw_edf(train_files[0], preload=False)\n",
    "sample_edf.info"
   ],
   "id": "569762c98a1f7205",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from C:\\Users\\mspla\\Documents\\repos\\py_basic_310_Au24\\seizurePy3.9\\data\\raw_data\\chb-mit-scalp-eeg-database-1.0.0\\chb01\\chb01_01.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mspla\\AppData\\Local\\Temp\\ipykernel_5836\\3700619184.py:4: RuntimeWarning: Channel names are not unique, found duplicates for: {'T8-P8'}. Applying running numbers for duplicates.\n",
      "  sample_edf = mne.io.read_raw_edf(train_files[0], preload=False)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Info | 8 non-empty values\n",
       " bads: []\n",
       " ch_names: FP1-F7, F7-T7, T7-P7, P7-O1, FP1-F3, F3-C3, C3-P3, P3-O1, ...\n",
       " chs: 23 EEG\n",
       " custom_ref_applied: False\n",
       " highpass: 0.0 Hz\n",
       " lowpass: 128.0 Hz\n",
       " meas_date: 2076-11-06 11:42:54 UTC\n",
       " nchan: 23\n",
       " projs: []\n",
       " sfreq: 256.0 Hz\n",
       " subject_info: 1 item (dict)\n",
       ">"
      ],
      "text/html": [
       "<script type=\"text/javascript\">\n",
       "    const toggleVisibility = (className) => {\n",
       "\n",
       "  const elements = document.querySelectorAll(`.${className}`)\n",
       "\n",
       "  elements.forEach(element => {\n",
       "    if (element.classList.contains('repr-section-header')) {\n",
       "      // Don't collapse the section header row.\n",
       "       return\n",
       "    }\n",
       "    if (element.classList.contains('repr-element-collapsed')) {\n",
       "      // Force a reflow to ensure the display change takes effect before removing the class\n",
       "      element.classList.remove('repr-element-collapsed')\n",
       "      element.offsetHeight // This forces the browser to recalculate layout\n",
       "      element.classList.remove('repr-element-faded')\n",
       "    } else {\n",
       "      // Start transition to hide the element\n",
       "      element.classList.add('repr-element-faded')\n",
       "      element.addEventListener('transitionend', handler = (e) => {\n",
       "        if (e.propertyName === 'opacity' && getComputedStyle(element).opacity === '0.2') {\n",
       "          element.classList.add('repr-element-collapsed')\n",
       "          element.removeEventListener('transitionend', handler)\n",
       "        }\n",
       "      });\n",
       "    }\n",
       "  });\n",
       "\n",
       "  // Take care of button (adjust caret)\n",
       "  const button = document.querySelectorAll(`.repr-section-header.${className} > th.repr-section-toggle-col > button`)[0]\n",
       "  button.classList.toggle('collapsed')\n",
       "\n",
       "  // Take care of the tooltip of the section header row\n",
       "  const sectionHeaderRow = document.querySelectorAll(`tr.repr-section-header.${className}`)[0]\n",
       "  sectionHeaderRow.classList.toggle('collapsed')\n",
       "  sectionHeaderRow.title = sectionHeaderRow.title === 'Hide section' ? 'Show section' : 'Hide section'\n",
       "}\n",
       "</script>\n",
       "\n",
       "<style type=\"text/css\">\n",
       "    table.repr.table.table-hover.table-striped.table-sm.table-responsive.small {\n",
       "  /* Don't make rows wider than they need to be. */\n",
       "  display: inline;\n",
       "}\n",
       "\n",
       "table > tbody > tr.repr-element > td {\n",
       "  /* Apply a tighter layout to the table cells. */\n",
       "  padding-top: 0.1rem;\n",
       "  padding-bottom: 0.1rem;\n",
       "  padding-right: 1rem;\n",
       "}\n",
       "\n",
       "table > tbody > tr > td.repr-section-toggle-col {\n",
       "  /* Remove background and border of the first cell in every row\n",
       "     (this row is only used for the collapse / uncollapse caret)\n",
       "\n",
       "     TODO: Need to find a good solution for VS Code that works in both\n",
       "           light and dark mode. */\n",
       "  border-color: transparent;\n",
       "  --bs-table-accent-bg: transparent;\n",
       "}\n",
       "\n",
       "tr.repr-section-header {\n",
       "  /* Remove stripes from section header rows */\n",
       "  background-color: transparent;\n",
       "  border-color: transparent;\n",
       "  --bs-table-striped-bg: transparent;\n",
       "  cursor: pointer;\n",
       "}\n",
       "\n",
       "tr.repr-section-header > th {\n",
       "  text-align: left !important;\n",
       "  vertical-align: middle;\n",
       "}\n",
       "\n",
       ".repr-element, tr.repr-element > td {\n",
       "  opacity: 1;\n",
       "  text-align: left !important;\n",
       "}\n",
       "\n",
       ".repr-element-faded {\n",
       "  transition: 0.3s ease;\n",
       "  opacity: 0.2;\n",
       "}\n",
       "\n",
       ".repr-element-collapsed {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "/* Collapse / uncollapse button and the caret it contains. */\n",
       ".repr-section-toggle-col button {\n",
       "  cursor: pointer;\n",
       "  width: 1rem;\n",
       "  background-color: transparent;\n",
       "  border-color: transparent;\n",
       "}\n",
       "\n",
       "span.collapse-uncollapse-caret {\n",
       "  width: 1rem;\n",
       "  height: 1rem;\n",
       "  display: block;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: left;\n",
       "  background-size: contain;\n",
       "}\n",
       "\n",
       "/* The collapse / uncollapse carets were copied from the free Font Awesome collection and adjusted. */\n",
       "\n",
       "/* Default to black carets for light mode */\n",
       ".repr-section-toggle-col > button.collapsed > span.collapse-uncollapse-caret {\n",
       "  background-image: url('data:image/svg+xml;charset=utf8,<svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 256 512\"><!--!Font Awesome Free 6.5.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free Copyright 2024 Fonticons, Inc.--><path fill=\"black\" d=\"M246.6 278.6c12.5-12.5 12.5-32.8 0-45.3l-128-128c-9.2-9.2-22.9-11.9-34.9-6.9s-19.8 16.6-19.8 29.6l0 256c0 12.9 7.8 24.6 19.8 29.6s25.7 2.2 34.9-6.9l128-128z\"/></svg>');\n",
       "}\n",
       "\n",
       ".repr-section-toggle-col\n",
       "  > button:not(.collapsed)\n",
       "  > span.collapse-uncollapse-caret {\n",
       "  background-image: url('data:image/svg+xml;charset=utf8,<svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 320 512\"><!--!Font Awesome Free 6.5.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free Copyright 2024 Fonticons, Inc.--><path fill=\"black\" d=\"M137.4 374.6c12.5 12.5 32.8 12.5 45.3 0l128-128c9.2-9.2 11.9-22.9 6.9-34.9s-16.6-19.8-29.6-19.8L32 192c-12.9 0-24.6 7.8-29.6 19.8s-2.2 25.7 6.9 34.9l128 128z\"/></svg>');\n",
       "}\n",
       "\n",
       "/* Use white carets for dark mode */\n",
       "@media (prefers-color-scheme: dark) {\n",
       "  .repr-section-toggle-col > button.collapsed > span.collapse-uncollapse-caret {\n",
       "    background-image: url('data:image/svg+xml;charset=utf8,<svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 256 512\"><!--!Font Awesome Free 6.5.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free Copyright 2024 Fonticons, Inc.--><path fill=\"white\" d=\"M246.6 278.6c12.5-12.5 12.5-32.8 0-45.3l-128-128c-9.2-9.2-22.9-11.9-34.9-6.9s-19.8 16.6-19.8 29.6l0 256c0 12.9 7.8 24.6 19.8 29.6s25.7 2.2 34.9-6.9l128-128z\"/></svg>');\n",
       "  }\n",
       "\n",
       "  .repr-section-toggle-col\n",
       "    > button:not(.collapsed)\n",
       "    > span.collapse-uncollapse-caret {\n",
       "    background-image: url('data:image/svg+xml;charset=utf8,<svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 320 512\"><!--!Font Awesome Free 6.5.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free Copyright 2024 Fonticons, Inc.--><path fill=\"white\" d=\"M137.4 374.6c12.5 12.5 32.8 12.5 45.3 0l128-128c9.2-9.2 11.9-22.9 6.9-34.9s-16.6-19.8-29.6-19.8L32 192c-12.9 0-24.6 7.8-29.6 19.8s-2.2 25.7 6.9 34.9l128 128z\"/></svg>');\n",
       "  }\n",
       "}\n",
       "\n",
       ".channel-names-btn {\n",
       "  padding: 0;\n",
       "  border: none;\n",
       "  background: none;\n",
       "  text-decoration: underline;\n",
       "  text-decoration-style: dashed;\n",
       "  cursor: pointer;\n",
       "  color: #0d6efd;\n",
       "}\n",
       "\n",
       ".channel-names-btn:hover {\n",
       "  color: #0a58ca;\n",
       "}\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "<table class=\"repr table table-hover table-striped table-sm table-responsive small\">\n",
       "    \n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "<tr class=\"repr-section-header general-3e41dd14-2ae6-4369-ae81-9b8e49b01114\"  title=\"Hide section\" \n",
       "    onclick=\"toggleVisibility('general-3e41dd14-2ae6-4369-ae81-9b8e49b01114')\">\n",
       "    <th class=\"repr-section-toggle-col\">\n",
       "        <button>\n",
       "            \n",
       "            <span class=\"collapse-uncollapse-caret\"></span>\n",
       "        </button>\n",
       "    </th>\n",
       "    <th colspan=\"2\">\n",
       "        <strong>General</strong>\n",
       "    </th>\n",
       "</tr>\n",
       "\n",
       "<tr class=\"repr-element general-3e41dd14-2ae6-4369-ae81-9b8e49b01114 \">\n",
       "    <td class=\"repr-section-toggle-col\"></td>\n",
       "    <td>MNE object type</td>\n",
       "    <td>Info</td>\n",
       "</tr>\n",
       "<tr class=\"repr-element general-3e41dd14-2ae6-4369-ae81-9b8e49b01114 \">\n",
       "    <td class=\"repr-section-toggle-col\"></td>\n",
       "    <td>Measurement date</td>\n",
       "    \n",
       "    <td>2076-11-06 at 11:42:54 UTC</td>\n",
       "    \n",
       "</tr>\n",
       "<tr class=\"repr-element general-3e41dd14-2ae6-4369-ae81-9b8e49b01114 \">\n",
       "    <td class=\"repr-section-toggle-col\"></td>\n",
       "    <td>Participant</td>\n",
       "    \n",
       "    \n",
       "    <td>Surrogate</td>\n",
       "    \n",
       "    \n",
       "</tr>\n",
       "<tr class=\"repr-element general-3e41dd14-2ae6-4369-ae81-9b8e49b01114 \">\n",
       "    <td class=\"repr-section-toggle-col\"></td>\n",
       "    <td>Experimenter</td>\n",
       "    \n",
       "    <td>Unknown</td>\n",
       "    \n",
       "</tr>\n",
       "    \n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "<tr class=\"repr-section-header acquisition-6d64b5d3-e0f7-4dfd-ac25-6481159d00d7\" \n",
       "    title=\"Hide section\"  onclick=\"toggleVisibility('acquisition-6d64b5d3-e0f7-4dfd-ac25-6481159d00d7')\">\n",
       "    <th class=\"repr-section-toggle-col\">\n",
       "        <button>\n",
       "            \n",
       "            <span class=\"collapse-uncollapse-caret\"></span>\n",
       "        </button>\n",
       "    </th>\n",
       "    <th colspan=\"2\">\n",
       "        <strong>Acquisition</strong>\n",
       "    </th>\n",
       "</tr>\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "<tr class=\"repr-element acquisition-6d64b5d3-e0f7-4dfd-ac25-6481159d00d7 \">\n",
       "    <td class=\"repr-section-toggle-col\"></td>\n",
       "    <td>Sampling frequency</td>\n",
       "    <td>256.00 Hz</td>\n",
       "</tr>\n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "<tr class=\"repr-section-header channels-f97b11fd-c274-4c23-b860-49cc0c2771d7\"  title=\"Hide section\" \n",
       "    onclick=\"toggleVisibility('channels-f97b11fd-c274-4c23-b860-49cc0c2771d7')\">\n",
       "    <th class=\"repr-section-toggle-col\">\n",
       "        <button>\n",
       "            \n",
       "            <span class=\"collapse-uncollapse-caret\"></span>\n",
       "        </button>\n",
       "    </th>\n",
       "    <th colspan=\"2\">\n",
       "        <strong>Channels</strong>\n",
       "    </th>\n",
       "</tr>\n",
       "\n",
       "\n",
       "<tr class=\"repr-element channels-f97b11fd-c274-4c23-b860-49cc0c2771d7 \">\n",
       "    <td class=\"repr-section-toggle-col\"></td>\n",
       "    <td>EEG</td>\n",
       "    <td>\n",
       "        <button class=\"channel-names-btn\" onclick=\"alert('Good EEG:\\n\\nFP1-F7, F7-T7, T7-P7, P7-O1, FP1-F3, F3-C3, C3-P3, P3-O1, FP2-F4, F4-C4, C4-P4, P4-O2, FP2-F8, F8-T8, T8-P8-0, P8-O2, FZ-CZ, CZ-PZ, P7-T7, T7-FT9, FT9-FT10, FT10-T8, T8-P8-1')\" title=\"(Click to open in popup)&#13;&#13;FP1-F7, F7-T7, T7-P7, P7-O1, FP1-F3, F3-C3, C3-P3, P3-O1, FP2-F4, F4-C4, C4-P4, P4-O2, FP2-F8, F8-T8, T8-P8-0, P8-O2, FZ-CZ, CZ-PZ, P7-T7, T7-FT9, FT9-FT10, FT10-T8, T8-P8-1\">\n",
       "            23\n",
       "        </button>\n",
       "\n",
       "        \n",
       "    </td>\n",
       "</tr>\n",
       "\n",
       "\n",
       "<tr class=\"repr-element channels-f97b11fd-c274-4c23-b860-49cc0c2771d7 \">\n",
       "    <td class=\"repr-section-toggle-col\"></td>\n",
       "    <td>Head & sensor digitization</td>\n",
       "    \n",
       "    <td>Not available</td>\n",
       "    \n",
       "</tr>\n",
       "    \n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "<tr class=\"repr-section-header filters-547e1f69-07ac-4be6-9266-44b973ca35b5\"  title=\"Hide section\" \n",
       "    onclick=\"toggleVisibility('filters-547e1f69-07ac-4be6-9266-44b973ca35b5')\">\n",
       "    <th class=\"repr-section-toggle-col\">\n",
       "        <button>\n",
       "            \n",
       "            <span class=\"collapse-uncollapse-caret\"></span>\n",
       "        </button>\n",
       "    </th>\n",
       "    <th colspan=\"2\">\n",
       "        <strong>Filters</strong>\n",
       "    </th>\n",
       "</tr>\n",
       "\n",
       "<tr class=\"repr-element filters-547e1f69-07ac-4be6-9266-44b973ca35b5 \">\n",
       "    <td class=\"repr-section-toggle-col\"></td>\n",
       "    <td>Highpass</td>\n",
       "    <td>0.00 Hz</td>\n",
       "</tr>\n",
       "\n",
       "\n",
       "<tr class=\"repr-element filters-547e1f69-07ac-4be6-9266-44b973ca35b5 \">\n",
       "    <td class=\"repr-section-toggle-col\"></td>\n",
       "    <td>Lowpass</td>\n",
       "    <td>128.00 Hz</td>\n",
       "</tr>\n",
       "\n",
       "\n",
       "</table>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-01T04:27:08.777175Z",
     "start_time": "2025-01-01T04:27:07.183483Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# identify montage used for surface electrode ( naming convention to identify each surface scalp electrode)\n",
    "sample_edf.describe()"
   ],
   "id": "73bf9703f3169dc0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<RawEDF | chb01_01.edf, 23 x 921600 (3600.0 s), ~27 kB, data not loaded>\n",
      "ch  name      type  unit        min         Q1     median         Q3        max\n",
      " 0  FP1-F7    EEG   µV      -807.03     -24.03      -1.37      19.73    1037.95\n",
      " 1  F7-T7     EEG   µV      -726.54     -17.00       0.20      17.00     549.55\n",
      " 2  T7-P7     EEG   µV      -544.47     -13.48       0.20      14.26     588.62\n",
      " 3  P7-O1     EEG   µV      -449.52     -10.74       0.59      11.53     206.11\n",
      " 4  FP1-F3    EEG   µV      -882.44     -26.37      -0.98      22.86     792.19\n",
      " 5  F3-C3     EEG   µV      -431.94     -14.65       0.20      15.04     402.25\n",
      " 6  C3-P3     EEG   µV      -417.09     -10.35       0.20      10.74     536.65\n",
      " 7  P3-O1     EEG   µV      -201.03     -13.48       0.20      14.26     229.94\n",
      " 8  FP2-F4    EEG   µV      -563.61     -24.03      -0.98      20.51     700.76\n",
      " 9  F4-C4     EEG   µV      -262.76     -13.48       0.20      13.48     235.41\n",
      "10  C4-P4     EEG   µV      -284.64     -10.35       0.20      11.14     400.29\n",
      "11  P4-O2     EEG   µV      -435.07     -13.48       0.20      14.26     694.11\n",
      "12  FP2-F8    EEG   µV      -654.65     -22.08      -0.98      18.17     963.32\n",
      "13  F8-T8     EEG   µV      -489.77     -17.78      -0.59      17.39     419.44\n",
      "14  T8-P8-0   EEG   µV      -626.91     -13.87       0.59      15.04     364.74\n",
      "15  P8-O2     EEG   µV      -474.92     -14.65       0.59      15.82     620.66\n",
      "16  FZ-CZ     EEG   µV      -199.46     -13.09       0.20      13.09     149.84\n",
      "17  CZ-PZ     EEG   µV      -195.16     -12.70       0.20      13.09     248.69\n",
      "18  P7-T7     EEG   µV      -588.23     -13.87       0.20      13.87     544.86\n",
      "19  T7-FT9    EEG   µV      -548.38     -13.48       0.98      14.26     764.05\n",
      "20  FT9-FT10  EEG   µV      -606.59     -20.51      -0.20      21.68     630.04\n",
      "21  FT10-T8   EEG   µV      -445.62     -12.70      -0.20      12.70     470.62\n",
      "22  T8-P8-1   EEG   µV      -626.91     -13.87       0.59      15.04     364.74\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-01T03:23:10.553436600Z",
     "start_time": "2025-01-01T03:21:25.805167Z"
    }
   },
   "cell_type": "code",
   "source": [
    "channel_labels = ['FP1-F7', 'F7-T7', 'T7-P7', 'P7-O1', 'FP1-F3', 'F3-C3', 'C3-P3','P3-O1',\n",
    "                  'FP2-F4', 'F4-C4', 'C4-P4', 'P4-O2', 'FP2-F8', 'F8-T8', 'T8-P8', 'P8-O2',\n",
    "                  'FZ-CZ', 'CZ-PZ', 'P7-T7', 'T7-FT9', 'FT9-FT10', 'FT10-T8', 'T8-P8-1']"
   ],
   "id": "46aaabedfd01431b",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### The international 10-20 systems defines placement of scalp electrodes.\n",
    "Older system use 18 pairs or 18 channels\n",
    "Newer ones may have 23,24 or 26 pairs.\n",
    "\n",
    "For this project we use 23 channels.\n",
    "\n"
   ],
   "id": "3e9fee2292681dbf"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "EEG files are a montage of amplitudes from channels.\n",
    "\n",
    "Each channel represents scalp electrode detection of brain signal amplitude. The montage is arranged from left to right, and front of scalp to back.\n",
    "The channels are labelled as\n",
    "\n",
    " ['FP1-F7', 'F7-T7', 'T7-P7', 'P7-O1', 'FP1-F3', 'F3-C3', 'C3-P3','P3-O1',\n",
    "\n",
    " 'FP2-F4', 'F4-C4', 'C4-P4', 'P4-O2', 'FP2-F8', 'F8-T8', 'T8-P8', 'P8-O2',\n",
    "\n",
    " 'FZ-CZ', 'CZ-PZ', 'P7-T7', 'T7-FT9', 'FT9-FT10', 'FT10-T8', 'T8-P8-1']"
   ],
   "id": "136174c9f9ea2c74"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Signal Extraction\n",
    "\n",
    "Codes extensively modified from work by [Mashahiro Goton](https://www.kaggle.com/code/hemangjindal/chb-mit-eeg-dataset-my-notebook#CHB-MIT-eeg-dataset-seizure-detection-demo). \\[Online] [Accesssed on 20 October 2024].\n",
    "\n",
    "EDfToNpy class contains:\n",
    "1. read_efd - read edf formatted seizure file. Identify parameters for creating numpy arrays. Ensure correct channels and calculate samples of seizure and non seizure files.\n",
    "2. extract_edf - create appropriate numpy arrays using arguments obtained from read_edf method. Copy data and labels to numpy array, then save to file as npy format.\n",
    "3. show_EEG - display EEG"
   ],
   "id": "85cc78864d88805b"
  },
  {
   "metadata": {},
   "cell_type": "raw",
   "source": [
    "'''\n",
    "Reading EEG data, modified from cell 60 of notebook by Masahiro Gotoh  [Online]\n",
    "[available at https://www.kaggle.com/code/hemangjindal/chb-mit-eeg-dataset-my-notebook#CHB-MIT-eeg-dataset-seizure-detection-demo]\n",
    "'''\n",
    "\n",
    "class EdfToNpy:\n",
    "    # constants\n",
    "    WINDOW_TIME = 10  # segment size in second\n",
    "    STEP_TIME = 5     # Step size in second\n",
    "    SEIZURE_PROPORTION = 0.01    # proportion of non seizure, data is imbalanced with less than 1% comprising seizure data, in term of total time from owner's documentations\n",
    "    TO_MICROVOLTS = 1e6\n",
    "    channel_labels = ['FP1-F7', 'F7-T7', 'T7-P7', 'P7-O1', 'FP1-F3', 'F3-C3', 'C3-P3','P3-O1',\n",
    "                      'FP2-F4', 'F4-C4', 'C4-P4', 'P4-O2', 'FP2-F8', 'F8-T8', 'T8-P8', 'P8-O2',\n",
    "                      'FZ-CZ', 'CZ-PZ', 'P7-T7', 'T7-FT9', 'FT9-FT10', 'FT10-T8', 'T8-P8-1']\n",
    "\n",
    "    def __init__(self, folder, save_to):\n",
    "        self.save_to = save_to\n",
    "        self.folder = folder\n",
    "\n",
    "    # read edf formatted file\n",
    "    def read_edf(self):\n",
    "        count=0 # samples with seizure plus samples without seizure * seizure proportion (down sampling to try to balance both class)\n",
    "        window_size=0\n",
    "\n",
    "        for file in self.folder:\n",
    "            edf_data = mne.io.read_raw_edf(file, preload=False)\n",
    "            edf_labels = edf_data.ch_names\n",
    "            # check all channel labels appear in edf_labels\n",
    "            # acceptss files which have all the\n",
    "            if sum([any([0 if re.match(c, l) is None else 1 for l in edf_labels]) for c in EdfToNpy.channel_labels]) == len(EdfToNpy.channel_labels):\n",
    "                sampling_freq = int(1/(edf_data.times[1]-edf_data.times[0]))\n",
    "                window_size = sampling_freq * EdfToNpy.WINDOW_TIME\n",
    "                window_stride = sampling_freq * EdfToNpy.STEP_TIME\n",
    "\n",
    "                # identity EEG signal with seizure. 'Seizure' appended to file name, and marked at time point of seizure activity inside file.\n",
    "                # has seizure marks seizure/non-seizure as (1/0) for every data point. Its size equals number of data points\n",
    "                has_seizure = np.zeros((edf_data.n_times,))\n",
    "                if os.path.exists(file + '.seizures'):\n",
    "                    has_annotation = wfdb.rdann(file, 'seizures')\n",
    "                    # has_annotation.sample e.g [10,20, 300,400] means marked seizure from sample 10-20 , and 300-400 . [start1,end1, start2,end2, ...]]\n",
    "                    for idx in range(int(has_annotation.sample.size / 2)):\n",
    "                        has_seizure[has_annotation.sample[idx * 2]:has_annotation.sample[idx * 2 + 1]] = 1\n",
    "\n",
    "                # create has seizure index, and calculate proportion of signal which shows seizures\n",
    "                # if a window segment contains some seizure in signal, that window segment is classified as having 'seizure'\n",
    "                has_seizure_idx = np.array([has_seizure[idx * window_stride:idx * window_stride + window_size].sum() / window_size for idx in range((edf_data.n_times - window_size) // window_stride)])\n",
    "\n",
    "                ### size of samples with and without seizure after subsampling\n",
    "                ### Data imbalance, normal EEG comprises 99% of data, multiplying by no seizure portion 0.01% allows down sampling of non seizure data\n",
    "                # np.where returns tuple of array of indices , np.where()[0] returns array of indices\n",
    "                noseizure_n_size = round(EdfToNpy.SEIZURE_PROPORTION * np.where(has_seizure_idx==0)[0].size)\n",
    "                seizure_n_size = np.where(has_seizure_idx > 0)[0].size\n",
    "                count = count + noseizure_n_size + seizure_n_size\n",
    "            edf_data.close()\n",
    "\n",
    "        return count, len(EdfToNpy.channel_labels), window_size\n",
    "\n",
    "    # segment data into 10-second window and save data to numpy data file. Also save seizure annotation to numpy label file.\n",
    "    def extract_edf(self, n_samples, n_channel_labels, window_size):\n",
    "        signals_np = np.zeros((n_samples, n_channel_labels, window_size), dtype=np.float32)\n",
    "        labels_np = np.zeros(n_samples, dtype=np.int32)\n",
    "\n",
    "        # Read  edf, rename file channel to match names from channel labels list. When files have multiple channel names, only first is picked.\n",
    "        for number, file in enumerate(self.folder):\n",
    "            log = f\"Reading file {number} \"\n",
    "            edf_data = mne.io.read_raw_edf(file, preload=False)\n",
    "\n",
    "            # accept edf files that have the pre-requisite channels as defined in EdfToNpy.channel_labels\n",
    "            n_label_match = sum([any([0 if re.match(ch, ch_name) is None else 1 for ch_name in edf_data.ch_names]) for ch in EdfToNpy.channel_labels])\n",
    "            if n_label_match == len(EdfToNpy.channel_labels):\n",
    "                # files may contain duplicate names\n",
    "                dict_ch_name = {sorted([ch_name for ch_name in edf_data.ch_names if re.match(ch, ch_name) is not None])[0]: ch for ch in EdfToNpy.channel_labels}\n",
    "                edf_data.rename_channels(dict_ch_name)\n",
    "\n",
    "                # Retrieve EEG (in microvolts) ,  annotations\n",
    "                has_seizure = np.zeros((edf_data.n_times,))\n",
    "                signals_ = edf_data.get_data(picks=EdfToNpy.channel_labels) * EdfToNpy.TO_MICROVOLTS\n",
    "\n",
    "                if  os.path.exists(file+'.seizures'):\n",
    "                    log = log + \"positive seizure\"\n",
    "                    has_annotation = wfdb.rdann(file, 'seizures')\n",
    "                    #\tsample returns array of indices where 'seizure' is annotated onto data file eg [[200,210],[260,270],...] indicating file annotated with 'seizure' from index 200 to 210, and from 260 to 270\n",
    "                    for idx in range(int(has_annotation.sample.size / 2)):\n",
    "                        has_seizure[has_annotation.sample[idx * 2]:has_annotation.sample[idx * 2 + 1]] = 1\n",
    "                else:\n",
    "                    log = log + \"negative seizure\"\n",
    "\n",
    "                # create seizure index, and calculate proportion of signal which shows seizures\n",
    "                sampling_freq = int(1/(edf_data.times[1]-edf_data.times[0]))\n",
    "                window_size = sampling_freq * EdfToNpy.WINDOW_TIME\n",
    "\n",
    "                window_stride = sampling_freq * EdfToNpy.STEP_TIME\n",
    "                has_seizure_idx = np.array([has_seizure[idx * window_stride:idx * window_stride + window_size].sum() / window_size for idx in range((edf_data.n_times - window_size) // window_stride)])\n",
    "\n",
    "                # populate numpy array with EEG , annotation data\n",
    "                noseizure_n_size = round(EdfToNpy.SEIZURE_PROPORTION * np.where(has_seizure_idx==0)[0].size)\n",
    "                seizure_n_size = np.where(has_seizure_idx > 0)[0].size\n",
    "\n",
    "\n",
    "                # non seizure data are by far larger than seizure data. To avoid overfitting, and bias, non seizure data is randomly sub-sampled. This prevents model from being overwhelmed by large non seizure data\n",
    "                count = 0\n",
    "                temp_negative = random.sample(list(np.where(has_seizure_idx == 0)[0]), noseizure_n_size)\n",
    "                for value in temp_negative:\n",
    "                    start_index = value * window_stride\n",
    "                    stop_index = value * window_stride + window_size\n",
    "                    signals_np[count, :, :] = signals_[:, start_index:stop_index ]\n",
    "\n",
    "                    labels_np[count] = 0\n",
    "                    count = count + 1\n",
    "                #seizure\n",
    "\n",
    "                temp_positive = list(np.where(has_seizure_idx > 0)[0])\n",
    "                for value in temp_positive:\n",
    "                    start_index = value * window_stride\n",
    "                    stop_index = value * window_stride + window_size\n",
    "                    signals_np[count, :, :] = signals_[:, start_index: stop_index]\n",
    "                    labels_np[count] = 1\n",
    "                    count = count + 1\n",
    "\n",
    "            else:\n",
    "                print(f\"Unable to read {file}\")\n",
    "\n",
    "            # close resource\n",
    "            edf_data.close()\n",
    "\n",
    "            # save signal and label files\n",
    "        np.save(self.save_to + '_signals', signals_np)\n",
    "        np.save(self.save_to + '_labels', labels_np)\n",
    "\n",
    "\n",
    "    def show_eeg(self, signals):\n",
    "        # show a sample of extracted signals\n",
    "\n",
    "        vertical_width = 250\n",
    "        fs = 256\n",
    "\n",
    "        fig, ax = plt.subplots()\n",
    "        for i in range(signals.shape[0]):\n",
    "            ax.plot(np.arange(signals.shape[-1])/fs, signals[i, :]+i*vertical_width, linewidth=0.5, color='tab:blue')\n",
    "            ax.annotate(EdfToNpy.channel_labels[i], xy=(0, i*vertical_width))\n",
    "        ax.invert_yaxis()\n",
    "        plt.show()\n"
   ],
   "id": "eec99947d98b7d0d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-16T09:19:51.640431Z",
     "start_time": "2025-01-16T09:19:51.612795Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class EdfToNpy:\n",
    "    # Constants\n",
    "    WINDOW_TIME = 10  # segment size in second\n",
    "    STEP_TIME = 5     # Step size in second\n",
    "    SEIZURE_PROPORTION = 0.01    # proportion of non seizure\n",
    "    TO_MICROVOLTS = 1e6\n",
    "    channel_labels = ['FP1-F7', 'F7-T7', 'T7-P7', 'P7-O1', 'FP1-F3', 'F3-C3', 'C3-P3', 'P3-O1',\n",
    "                      'FP2-F4', 'F4-C4', 'C4-P4', 'P4-O2', 'FP2-F8', 'F8-T8', 'T8-P8', 'P8-O2',\n",
    "                      'FZ-CZ', 'CZ-PZ', 'P7-T7', 'T7-FT9', 'FT9-FT10', 'FT10-T8', 'T8-P8-1']\n",
    "\n",
    "    def __init__(self, folder, save_to):\n",
    "        self.save_to = save_to\n",
    "        self.folder = folder\n",
    "\n",
    "    # Read edf formatted file\n",
    "    def read_edf(self):\n",
    "        count = 0  # initialize the count variable\n",
    "        window_size = 0  # initialize the window_size variable\n",
    "\n",
    "        for file in self.folder:\n",
    "            edf_data = mne.io.read_raw_edf(file, preload=False)\n",
    "            edf_labels = edf_data.ch_names\n",
    "\n",
    "            if sum([any([0 if re.match(c, l) is None else 1 for l in edf_labels]) for c in EdfToNpy.channel_labels]) == len(EdfToNpy.channel_labels):\n",
    "                sampling_freq = int(1 / (edf_data.times[1] - edf_data.times[0]))\n",
    "                window_size = sampling_freq * EdfToNpy.WINDOW_TIME\n",
    "                window_stride = sampling_freq * EdfToNpy.STEP_TIME\n",
    "\n",
    "                has_seizure = np.zeros((edf_data.n_times,))\n",
    "                if os.path.exists(file + '.seizures'):\n",
    "                    has_annotation = wfdb.rdann(file, 'seizures')\n",
    "                    for idx in range(int(has_annotation.sample.size / 2)):\n",
    "                        has_seizure[has_annotation.sample[idx * 2]:has_annotation.sample[idx * 2 + 1]] = 1\n",
    "\n",
    "                has_seizure_idx = np.array([has_seizure[idx * window_stride:idx * window_stride + window_size].sum() / window_size for idx in range((edf_data.n_times - window_size) // window_stride)])\n",
    "\n",
    "                noseizure_n_size = round(EdfToNpy.SEIZURE_PROPORTION * np.where(has_seizure_idx == 0)[0].size)\n",
    "                seizure_n_size = np.where(has_seizure_idx > 0)[0].size\n",
    "                count = count + noseizure_n_size + seizure_n_size  # increment count to tally total samples\n",
    "\n",
    "            edf_data.close()\n",
    "\n",
    "        return count, len(EdfToNpy.channel_labels), window_size\n",
    "\n",
    "    # Segment data into 10-second window and save data to numpy data file. Also save seizure annotation to numpy label file.\n",
    "    def extract_edf(self, n_samples, n_channel_labels, window_size):\n",
    "        signals_np = np.zeros((n_samples, n_channel_labels, window_size), dtype=np.float32)\n",
    "        labels_np = np.zeros(n_samples, dtype=np.int32)\n",
    "        count = 0  # initialize the count variable\n",
    "\n",
    "        for number, file in enumerate(self.folder):\n",
    "            edf_data = mne.io.read_raw_edf(file, preload=False)\n",
    "\n",
    "            n_label_match = sum([any([0 if re.match(ch, ch_name) is None else 1 for ch_name in edf_data.ch_names]) for ch in EdfToNpy.channel_labels])\n",
    "            if n_label_match == len(EdfToNpy.channel_labels):\n",
    "                dict_ch_name = {sorted([ch_name for ch_name in edf_data.ch_names if re.match(ch, ch_name) is not None])[0]: ch for ch in EdfToNpy.channel_labels}\n",
    "                edf_data.rename_channels(dict_ch_name)\n",
    "\n",
    "                has_seizure = np.zeros((edf_data.n_times,))\n",
    "                signals_ = edf_data.get_data(picks=EdfToNpy.channel_labels) * EdfToNpy.TO_MICROVOLTS\n",
    "\n",
    "                if os.path.exists(file + '.seizures'):\n",
    "                    has_annotation = wfdb.rdann(file, 'seizures')\n",
    "                    for idx in range(int(has_annotation.sample.size / 2)):\n",
    "                        has_seizure[has_annotation.sample[idx * 2]:has_annotation.sample[idx * 2 + 1]] = 1\n",
    "\n",
    "                sampling_freq = int(1 / (edf_data.times[1] - edf_data.times[0]))\n",
    "                window_size = sampling_freq * EdfToNpy.WINDOW_TIME\n",
    "                window_stride = sampling_freq * EdfToNpy.STEP_TIME\n",
    "                has_seizure_idx = np.array([has_seizure[idx * window_stride:idx * window_stride + window_size].sum() / window_size for idx in range((edf_data.n_times - window_size) // window_stride)])\n",
    "\n",
    "                noseizure_n_size = round(EdfToNpy.SEIZURE_PROPORTION * np.where(has_seizure_idx == 0)[0].size)\n",
    "                seizure_n_size = np.where(has_seizure_idx > 0)[0].size\n",
    "\n",
    "                # Non-seizure data\n",
    "                temp_negative = random.sample(list(np.where(has_seizure_idx == 0)[0]), noseizure_n_size)  # sample non-seizure data correctly\n",
    "                for value in temp_negative:\n",
    "                    start_index = value * window_stride\n",
    "                    stop_index = value * window_stride + window_size\n",
    "                    signals_np[count, :, :] = signals_[:, start_index:stop_index]\n",
    "                    labels_np[count] = 0\n",
    "                    count = count + 1\n",
    "\n",
    "                # Seizure data\n",
    "                temp_positive = list(np.where(has_seizure_idx > 0)[0])  # sample seizure data correctly\n",
    "                for value in temp_positive:\n",
    "                    start_index = value * window_stride\n",
    "                    stop_index = value * window_stride + window_size\n",
    "                    signals_np[count, :, :] = signals_[:, start_index:stop_index]\n",
    "                    labels_np[count] = 1\n",
    "                    count = count + 1\n",
    "            else:\n",
    "                print(f\"Unable to read {file}\")\n",
    "\n",
    "            edf_data.close()\n",
    "\n",
    "        np.save(self.save_to + '_signals', signals_np)\n",
    "        np.save(self.save_to + '_labels', labels_np)\n",
    "\n",
    "    def show_eeg(self, signals):\n",
    "        vertical_width = 250\n",
    "        fs = 256\n",
    "\n",
    "        fig, ax = plt.subplots()\n",
    "        for i in range(signals.shape[0]):\n",
    "            ax.plot(np.arange(signals.shape[-1]) / fs, signals[i, :] + i * vertical_width, linewidth=0.5, color='tab:blue')\n",
    "            ax.annotate(EdfToNpy.channel_labels[i], xy=(0, i * vertical_width))\n",
    "        ax.invert_yaxis()\n",
    "        plt.show()"
   ],
   "id": "96dfc893926d4748",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-01T03:23:10.553436600Z",
     "start_time": "2025-01-01T03:21:25.962116Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "6c7ce9243e38e5de",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 5-6 minutes to run cell\n",
    "# extract data into training numpy file\n",
    "\n",
    "# Instantiate class\n",
    "train_npy =  EdfToNpy(train_files, 'train_10sec')\n",
    "\n",
    "# Get training samples\n",
    "sample_length, channel_length, window_length = train_npy.read_edf()\n",
    "train_npy.extract_edf(sample_length, channel_length, window_length)"
   ],
   "id": "e70d06a18215e13e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "9882507e4466fa14",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 1-2 minutes to run cell\n",
    "# extract remaining portion into testing numpy file\n",
    "\n",
    "# Instantiate class\n",
    "test_npy = EdfToNpy(test_files, 'test_10sec')\n",
    "# Get training samples\n",
    "sample_length, channel_length, window_length = test_npy.read_edf()\n",
    "test_npy.extract_edf(sample_length, channel_length, window_length)\n",
    "\n"
   ],
   "id": "76fc334939722bab",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "5cb348539ae0ff76",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "raw",
   "source": "",
   "id": "e1fe01556f81fab4",
   "outputs": null,
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### First Iteration",
   "id": "65e09e005adf1f30"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Successfully implemented reading and converting raw edf format to numpy format during prototyping.\n",
    "\n",
    "EdfToNumpy class is created to contain those methods.\n",
    "\n",
    "Raw data is segmented into 10 second windows for each sample."
   ],
   "id": "df493b7aac55c3b9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-01T03:43:08.248823Z",
     "start_time": "2025-01-01T03:43:08.223671Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Check numpy files are readable\n",
    "# Training data\n",
    "path_signal = 'train_10sec_signals.npy'\n",
    "path_label = 'train_10sec_labels.npy'\n",
    "if os.path.exists(path_label):\n",
    "    train_labels = np.load(path_label)\n",
    "    unique, count = np.unique(train_labels, return_counts=True)\n",
    "    print(f\"Train labels {unique} contain {count}\")\n",
    "\n",
    "# Testing  data\n",
    "path_signal = 'test_10sec_signals.npy'\n",
    "path_label = 'test_10sec_labels.npy'\n",
    "if os.path.exists(path_label):\n",
    "    test_labels = np.load(path_label)\n",
    "    unique, count = np.unique(test_labels, return_counts=True)\n",
    "    print(f\"Test labels {unique} contains {count}\")\n",
    "\n"
   ],
   "id": "a27613cae92a2c7d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train labels [0 1] contain [9190  119]\n",
      "Test labels [0 1] contains [2307  186]\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Problems\n",
    "\n",
    "Current train-test samples are splitted by folder or case number.\n",
    "\n",
    "Each case may have different seizure type. Different seizure types have different signal signatures.\n",
    "\n",
    "Therefore training and testing are likely to have different seizure signature.\n",
    "\n",
    "Training sample presented to classifier will not be representative of all seizure types in the entire CHB-Mit seizure dataset.\n",
    "\n",
    "> To overcome this initial mistake, the entire CHB-MIT dataset is segmented into 10-second window samples and converted to a single numpy signal file, and corresponding numpy label file."
   ],
   "id": "96555c71e5719659"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-16T09:22:06.617996Z",
     "start_time": "2025-01-16T09:22:06.604934Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Check numpy files are readable\n",
    "# Retrieve all edf files contained within parent folder - \"data_folders\"\n",
    "\n",
    "all_edf = [ file for folder in data_folders for file in glob.glob(folder + '/*.edf')]\n",
    "print(f\"Total number of files is {len(all_edf)}\")"
   ],
   "id": "c438e12afeeac0ab",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of files is 686\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 8-9 minutes to run cell\n",
    "\n",
    "# Instantiate class\n",
    "data_npy = EdfToNpy(all_edf, '10sec')\n",
    "# Export all edf file data into single numpy 10-second window per sample file - \"10sec_signals.npy\"\n",
    "# Export annotations into corresponding \"10sec_labels.npy\", with 1 for seizure and 0 for non-seizure. Corresponds to each signal sample.\n",
    "sample_length, channel_length, window_length = data_npy.read_edf()\n",
    "data_npy.extract_edf(sample_length, channel_length, window_length)"
   ],
   "id": "a128507273215948",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "####  10sec_labels.npy",
   "id": "57a947b0ab37ed25"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-16T09:41:16.674541Z",
     "start_time": "2025-01-16T09:41:15.204119Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Check numpy files are readable\n",
    "\n",
    "path_signal = '10sec_signals.npy'\n",
    "path_label = '10sec_labels.npy'\n",
    "if os.path.exists(path_signal) and os.path.exists(path_label):\n",
    "    full_data = np.load(path_signal)\n",
    "    full_labels = np.load(path_label)\n",
    "\n",
    "    unique, count = np.unique(full_labels, return_counts=True)\n",
    "    print(f\"Labels contain {count[0]} non-seizure samples and {count[1]} seizure samples\")\n",
    "    print(f\"Data shape is {full_data.shape}\")\n",
    "    print(f\"Labels' shape is {full_labels.shape}\")\n",
    "\n"
   ],
   "id": "9381ce7067d9fbd4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels contain 8547 non-seizure samples and 3255 seizure samples\n",
      "Data shape is (11802, 23, 2560)\n",
      "Labels' shape is (11802,)\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "8909beedc090090f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### END",
   "id": "25723fef96db754a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "7c1aef8abef019c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "e01573b4c75049d6"
  },
  {
   "metadata": {},
   "cell_type": "raw",
   "source": [
    "\n",
    "'''\n",
    "\n",
    "# Configuration\n",
    "csv_folder = '/kaggle/working/csv_files'  # Folder containing the merged CSV file\n",
    "# eeg_channels = ['Channel_1', 'Channel_13', 'Channel_19', 'Channel_23']  # Channels to use\n",
    "eeg_channels = ['Channel_5', 'Channel_15', 'Channel_3', 'Channel_2']  # Channels to use\n",
    "\n",
    "window_size_sec = 5  # Window size in seconds\n",
    "step_size_sec = 2 # Step size in seconds\n",
    "sampling_rate = 16  # Sampling rate of EEG signals in Hz\n",
    "preictal_label = 1\n",
    "interictal_label = 0\n",
    "\n",
    "# Derived parameters\n",
    "window_size = window_size_sec * sampling_rate  # Convert to samples\n",
    "step_size = step_size_sec * sampling_rate  # Convert to samples\n",
    "\n",
    "# Function to load and prepare data\n",
    "def load_and_prepare_data(csv_file):\n",
    "    \"\"\"\n",
    "    Load the merged CSV data and prepare it for LSTM model training.\n",
    "    \"\"\"\n",
    "    data = pd.read_csv(csv_file)\n",
    "\n",
    "    # Normalize the EEG data (Min-Max scaling)\n",
    "    scaler = MinMaxScaler()\n",
    "    eeg_data = data[eeg_channels].values\n",
    "    eeg_data_scaled = scaler.fit_transform(eeg_data)\n",
    "\n",
    "    # Get the labels\n",
    "    labels = data['Label'].values\n",
    "\n",
    "    # Create sliding windows\n",
    "    windows, window_labels = create_windows(eeg_data_scaled, labels, window_size, step_size)\n",
    "\n",
    "    return windows, window_labels, scaler\n",
    "\n",
    "# Function to create windows from the data\n",
    "def create_windows(data, labels, window_size, step_size):\n",
    "    \"\"\"\n",
    "    Create overlapping windows from EEG data and corresponding labels.\n",
    "    \"\"\"\n",
    "    windows = []\n",
    "    window_labels = []\n",
    "\n",
    "    for start in range(0, len(data) - window_size + 1, step_size):\n",
    "        end = start + window_size\n",
    "        window = data[start:end, :]\n",
    "        label = labels[start:end]\n",
    "\n",
    "        # Assign label based on majority class in the window\n",
    "        window_label = preictal_label if np.sum(label == preictal_label) > len(label) // 2 else interictal_label\n",
    "        windows.append(window)\n",
    "        window_labels.append(window_label)\n",
    "\n",
    "    return np.array(windows), np.array(window_labels)\n",
    "\n",
    "# Function to build the LSTM model\n",
    "def build_lstm_model(input_shape):\n",
    "    \"\"\"\n",
    "    Build and compile an LSTM model.\n",
    "    \"\"\"\n",
    "    print('Input shape-',input_shape)\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=64, return_sequences=True, input_shape=input_shape))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(units=32, return_sequences=False))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(units=1, activation='sigmoid'))  # Output layer with sigmoid for binary classification\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Function to train the LSTM model\n",
    "def train_lstm_model(windows, window_labels):\n",
    "    \"\"\"\n",
    "    Train the LSTM model using the provided windows and labels.\n",
    "    \"\"\"\n",
    "    # Split data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(windows, window_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Build and train the model\n",
    "    model = build_lstm_model((X_train.shape[1], X_train.shape[2]))\n",
    "    model.fit(X_train, y_train, epochs=10, batch_size=64, validation_split=0.2)\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred = (y_pred > 0.5).astype(int)  # Convert probabilities to binary labels\n",
    "\n",
    "    # Print classification report\n",
    "    print(\"Classification Report on Test Data:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    # Return the trained model\n",
    "    return model, scaler\n",
    "\n",
    "# Real-time prediction function\n",
    "def real_time_prediction(model, scaler, window_size, interval=30):\n",
    "    \"\"\"\n",
    "    Simulate real-time predictions every `interval` seconds using the trained LSTM model.\n",
    "    \"\"\"\n",
    "    print(f\"Starting real-time prediction... (Interval: {interval}s)\")\n",
    "\n",
    "    # Simulate receiving new data (use the merged data as a placeholder)\n",
    "    while True:\n",
    "        # Simulate receiving data\n",
    "        # Replace this with real-time data fetching process\n",
    "        # For now, we assume the data is available in 'merged_df'\n",
    "        # Here we can simulate a chunk of data for prediction\n",
    "        simulated_data = np.random.rand(window_size, len(eeg_channels))  # Simulating new data\n",
    "\n",
    "        # Normalize the new data\n",
    "        scaled_data = scaler.transform(simulated_data)\n",
    "\n",
    "        # Reshape data to match LSTM input shape\n",
    "        X_input = scaled_data.reshape(1, window_size, len(eeg_channels))\n",
    "\n",
    "        # Predict the probability of seizure (preictal)\n",
    "        prediction = model.predict(X_input)\n",
    "        print(f\"Predicted probability of seizure: {prediction[0][0]:.4f}\")\n",
    "\n",
    "        # Sleep for the specified interval (simulate 30 seconds)\n",
    "        time.sleep(interval)\n",
    "\n",
    "# Main function\n",
    "if __name__ == \"__main__\":\n",
    "    # Load the merged data\n",
    "    csv_file = '/kaggle/working/csv_files/merged_data.csv'\n",
    "    windows, window_labels, scaler = load_and_prepare_data(csv_file)\n",
    "\n",
    "    # Train the LSTM model and evaluate on the test data\n",
    "    model, scaler = train_lstm_model(windows, window_labels)\n",
    "\n",
    "    # Save the model for later use\n",
    "    model.save('/kaggle/working/lstm_model.h5')\n",
    "    print(\"Model saved to /kaggle/working/lstm_model.h5\")\n",
    "\n",
    "    # Start real-time prediction\n",
    "    real_time_prediction(model, scaler, window_size, interval=30)\n",
    "\n",
    "'''"
   ],
   "id": "ab87c18baa38e8c6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "6646331cc1f543b7",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
