{
 "cells": [
  {
   "metadata": {},
   "cell_type": "raw",
   "source": [
    "Raw data are 42.6 GB in Edf format. Convert to csv for smaller size, and easier processing.\n",
    "1 Import mne and pandas library.\n",
    "2 mne.io.read_raw_edf to read each Edf file.\n",
    "3 mne.io.read_raw_edf.get_data to retrive read data.\n",
    "4 convert to numpy using  numpy.vstack. Vertical stack converts dimenstions into ssamples x features. This allow preprocessing\n",
    "5 save as csv using pandas.DataFrame.to_csv"
   ],
   "id": "9d8f5429570529c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-15T13:36:06.924002Z",
     "start_time": "2024-12-15T13:35:58.630556Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import mne # reads edf format\n",
    "import glob\n",
    "import random\n",
    "import re\n",
    "import wfdb # waveform database library wfdb.rdann reads annotation of physiology annotated data in ECG, EEG etc\n",
    "import tqdm # time bar"
   ],
   "id": "9e3119ec8ee92a61",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "raw",
   "source": [
    "Retrive data from Edf file. EEG files are a montage of amplitudes from channels. Each channel represents scalp electrode detection of brain signal amplitude. The montage is arranged from left to right, and front of scalp to back.\n",
    "The channels are labelled as\n",
    "['FP1-F7', 'F7-T7', 'T7-P7', 'P7-O1', 'FP1-F3', 'F3-C3', 'C3-P3','P3-O1',\n",
    " 'FP2-F4', 'F4-C4', 'C4-P4', 'P4-O2', 'FP2-F8', 'F8-T8', 'T8-P8', 'P8-O2',\n",
    " 'FZ-CZ', 'CZ-PZ']\n"
   ],
   "id": "765460765ea4c7d4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-15T13:37:16.490811Z",
     "start_time": "2024-12-15T13:37:16.484790Z"
    }
   },
   "cell_type": "code",
   "source": [
    "channel_labels = ['FP1-F7', 'F7-T7', 'T7-P7', 'P7-O1', 'FP1-F3', 'F3-C3', 'C3-P3','P3-O1',\n",
    "                  'FP2-F4', 'F4-C4', 'C4-P4', 'P4-O2', 'FP2-F8', 'F8-T8', 'T8-P8', 'P8-O2',\n",
    "                  'FZ-CZ', 'CZ-PZ']"
   ],
   "id": "d5fc00441f77703f",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "raw",
   "source": [
    "raw_data = \"raw_CHB-Mit\"\n",
    "patient name in filename ending with digit from chb01 - chb24"
   ],
   "id": "101877bfd0bfca0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-15T13:37:18.130637Z",
     "start_time": "2024-12-15T13:37:18.124436Z"
    }
   },
   "cell_type": "code",
   "source": [
    "path = r'data\\raw_data\\chb-mit-scalp-eeg-database-1.0.0'\n",
    "data_folders = sorted(glob.glob(os.path.join(path, '*[0-9]')))\n",
    "\n",
    "def file_id(folder):\n",
    "    return [ name[-2:] for name in [file.rsplit('\\\\',2)[-1] for file in folder]]\n",
    "print(\"ID: \")\n",
    "print(file_id(data_folders))"
   ],
   "id": "b797d0c19547718a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: \n",
      "['01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24']\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-15T13:37:20.782761Z",
     "start_time": "2024-12-15T13:37:20.770974Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# seizure  marking is in name of edf file, not a separate file\n",
    "# split files for training and testing\n",
    "train_test_ratio = 0.8\n",
    "random.seed(80)\n",
    "train_folders = sorted(random.sample(data_folders, round(len(data_folders) * train_test_ratio)))\n",
    "test_folders = sorted([ file for file in data_folders if file not in train_folders])\n",
    "print(f\"Training files ID: {file_id(train_folders)}\")\n",
    "print(f\"Test files ID: {file_id(test_folders)}\")\n",
    "\n"
   ],
   "id": "2bc6e28cdb2717b3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training files ID: ['01', '02', '04', '07', '08', '09', '10', '12', '13', '14', '15', '16', '17', '18', '19', '20', '22', '23', '24']\n",
      "Test files ID: ['03', '05', '06', '11', '21']\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-15T13:37:24.787210Z",
     "start_time": "2024-12-15T13:37:24.771357Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Retrieve edf files\n",
    "\n",
    "train_files = [ file for folder in train_folders for file in glob.glob(folder+'/*.edf')]\n",
    "test_files = [ file for folder in test_folders for file in glob.glob(folder+'/*.edf')]\n",
    "\n",
    "print(f\"Train_files contains {len(train_files)} files\")\n",
    "print(f\"Test_files contains {len(test_files)} files\")"
   ],
   "id": "c918f7ef2f9a282f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_files contains 523 files\n",
      "Test_files contains 163 files\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-15T13:37:43.033524Z",
     "start_time": "2024-12-15T13:37:30.436432Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# MEG and EEG library (mne) reads neurophysiological data\n",
    "sample_edf = mne.io.read_raw_edf(train_files[0], preload=False) #110-15 seconds\n",
    "# dir(sample_edf)  # show all attributes and methods\n",
    "sample_edf.info"
   ],
   "id": "569762c98a1f7205",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from C:\\Users\\mspla\\Documents\\repos\\py_basic_310_Au24\\seizurePy3.9\\data\\raw_data\\chb-mit-scalp-eeg-database-1.0.0\\chb01\\chb01_01.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mspla\\AppData\\Local\\Temp\\ipykernel_11760\\922965260.py:2: RuntimeWarning: Channel names are not unique, found duplicates for: {'T8-P8'}. Applying running numbers for duplicates.\n",
      "  sample_edf = mne.io.read_raw_edf(train_files[0], preload=False) #110-15 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Info | 8 non-empty values\n",
       " bads: []\n",
       " ch_names: FP1-F7, F7-T7, T7-P7, P7-O1, FP1-F3, F3-C3, C3-P3, P3-O1, ...\n",
       " chs: 23 EEG\n",
       " custom_ref_applied: False\n",
       " highpass: 0.0 Hz\n",
       " lowpass: 128.0 Hz\n",
       " meas_date: 2076-11-06 11:42:54 UTC\n",
       " nchan: 23\n",
       " projs: []\n",
       " sfreq: 256.0 Hz\n",
       " subject_info: 1 item (dict)\n",
       ">"
      ],
      "text/html": [
       "<script type=\"text/javascript\">\n",
       "    const toggleVisibility = (className) => {\n",
       "\n",
       "  const elements = document.querySelectorAll(`.${className}`)\n",
       "\n",
       "  elements.forEach(element => {\n",
       "    if (element.classList.contains('repr-section-header')) {\n",
       "      // Don't collapse the section header row.\n",
       "       return\n",
       "    }\n",
       "    if (element.classList.contains('repr-element-collapsed')) {\n",
       "      // Force a reflow to ensure the display change takes effect before removing the class\n",
       "      element.classList.remove('repr-element-collapsed')\n",
       "      element.offsetHeight // This forces the browser to recalculate layout\n",
       "      element.classList.remove('repr-element-faded')\n",
       "    } else {\n",
       "      // Start transition to hide the element\n",
       "      element.classList.add('repr-element-faded')\n",
       "      element.addEventListener('transitionend', handler = (e) => {\n",
       "        if (e.propertyName === 'opacity' && getComputedStyle(element).opacity === '0.2') {\n",
       "          element.classList.add('repr-element-collapsed')\n",
       "          element.removeEventListener('transitionend', handler)\n",
       "        }\n",
       "      });\n",
       "    }\n",
       "  });\n",
       "\n",
       "  // Take care of button (adjust caret)\n",
       "  const button = document.querySelectorAll(`.repr-section-header.${className} > th.repr-section-toggle-col > button`)[0]\n",
       "  button.classList.toggle('collapsed')\n",
       "\n",
       "  // Take care of the tooltip of the section header row\n",
       "  const sectionHeaderRow = document.querySelectorAll(`tr.repr-section-header.${className}`)[0]\n",
       "  sectionHeaderRow.classList.toggle('collapsed')\n",
       "  sectionHeaderRow.title = sectionHeaderRow.title === 'Hide section' ? 'Show section' : 'Hide section'\n",
       "}\n",
       "</script>\n",
       "\n",
       "<style type=\"text/css\">\n",
       "    table.repr.table.table-hover.table-striped.table-sm.table-responsive.small {\n",
       "  /* Don't make rows wider than they need to be. */\n",
       "  display: inline;\n",
       "}\n",
       "\n",
       "table > tbody > tr.repr-element > td {\n",
       "  /* Apply a tighter layout to the table cells. */\n",
       "  padding-top: 0.1rem;\n",
       "  padding-bottom: 0.1rem;\n",
       "  padding-right: 1rem;\n",
       "}\n",
       "\n",
       "table > tbody > tr > td.repr-section-toggle-col {\n",
       "  /* Remove background and border of the first cell in every row\n",
       "     (this row is only used for the collapse / uncollapse caret)\n",
       "\n",
       "     TODO: Need to find a good solution for VS Code that works in both\n",
       "           light and dark mode. */\n",
       "  border-color: transparent;\n",
       "  --bs-table-accent-bg: transparent;\n",
       "}\n",
       "\n",
       "tr.repr-section-header {\n",
       "  /* Remove stripes from section header rows */\n",
       "  background-color: transparent;\n",
       "  border-color: transparent;\n",
       "  --bs-table-striped-bg: transparent;\n",
       "  cursor: pointer;\n",
       "}\n",
       "\n",
       "tr.repr-section-header > th {\n",
       "  text-align: left !important;\n",
       "  vertical-align: middle;\n",
       "}\n",
       "\n",
       ".repr-element, tr.repr-element > td {\n",
       "  opacity: 1;\n",
       "  text-align: left !important;\n",
       "}\n",
       "\n",
       ".repr-element-faded {\n",
       "  transition: 0.3s ease;\n",
       "  opacity: 0.2;\n",
       "}\n",
       "\n",
       ".repr-element-collapsed {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "/* Collapse / uncollapse button and the caret it contains. */\n",
       ".repr-section-toggle-col button {\n",
       "  cursor: pointer;\n",
       "  width: 1rem;\n",
       "  background-color: transparent;\n",
       "  border-color: transparent;\n",
       "}\n",
       "\n",
       "span.collapse-uncollapse-caret {\n",
       "  width: 1rem;\n",
       "  height: 1rem;\n",
       "  display: block;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: left;\n",
       "  background-size: contain;\n",
       "}\n",
       "\n",
       "/* The collapse / uncollapse carets were copied from the free Font Awesome collection and adjusted. */\n",
       "\n",
       "/* Default to black carets for light mode */\n",
       ".repr-section-toggle-col > button.collapsed > span.collapse-uncollapse-caret {\n",
       "  background-image: url('data:image/svg+xml;charset=utf8,<svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 256 512\"><!--!Font Awesome Free 6.5.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free Copyright 2024 Fonticons, Inc.--><path fill=\"black\" d=\"M246.6 278.6c12.5-12.5 12.5-32.8 0-45.3l-128-128c-9.2-9.2-22.9-11.9-34.9-6.9s-19.8 16.6-19.8 29.6l0 256c0 12.9 7.8 24.6 19.8 29.6s25.7 2.2 34.9-6.9l128-128z\"/></svg>');\n",
       "}\n",
       "\n",
       ".repr-section-toggle-col\n",
       "  > button:not(.collapsed)\n",
       "  > span.collapse-uncollapse-caret {\n",
       "  background-image: url('data:image/svg+xml;charset=utf8,<svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 320 512\"><!--!Font Awesome Free 6.5.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free Copyright 2024 Fonticons, Inc.--><path fill=\"black\" d=\"M137.4 374.6c12.5 12.5 32.8 12.5 45.3 0l128-128c9.2-9.2 11.9-22.9 6.9-34.9s-16.6-19.8-29.6-19.8L32 192c-12.9 0-24.6 7.8-29.6 19.8s-2.2 25.7 6.9 34.9l128 128z\"/></svg>');\n",
       "}\n",
       "\n",
       "/* Use white carets for dark mode */\n",
       "@media (prefers-color-scheme: dark) {\n",
       "  .repr-section-toggle-col > button.collapsed > span.collapse-uncollapse-caret {\n",
       "    background-image: url('data:image/svg+xml;charset=utf8,<svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 256 512\"><!--!Font Awesome Free 6.5.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free Copyright 2024 Fonticons, Inc.--><path fill=\"white\" d=\"M246.6 278.6c12.5-12.5 12.5-32.8 0-45.3l-128-128c-9.2-9.2-22.9-11.9-34.9-6.9s-19.8 16.6-19.8 29.6l0 256c0 12.9 7.8 24.6 19.8 29.6s25.7 2.2 34.9-6.9l128-128z\"/></svg>');\n",
       "  }\n",
       "\n",
       "  .repr-section-toggle-col\n",
       "    > button:not(.collapsed)\n",
       "    > span.collapse-uncollapse-caret {\n",
       "    background-image: url('data:image/svg+xml;charset=utf8,<svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 320 512\"><!--!Font Awesome Free 6.5.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free Copyright 2024 Fonticons, Inc.--><path fill=\"white\" d=\"M137.4 374.6c12.5 12.5 32.8 12.5 45.3 0l128-128c9.2-9.2 11.9-22.9 6.9-34.9s-16.6-19.8-29.6-19.8L32 192c-12.9 0-24.6 7.8-29.6 19.8s-2.2 25.7 6.9 34.9l128 128z\"/></svg>');\n",
       "  }\n",
       "}\n",
       "\n",
       ".channel-names-btn {\n",
       "  padding: 0;\n",
       "  border: none;\n",
       "  background: none;\n",
       "  text-decoration: underline;\n",
       "  text-decoration-style: dashed;\n",
       "  cursor: pointer;\n",
       "  color: #0d6efd;\n",
       "}\n",
       "\n",
       ".channel-names-btn:hover {\n",
       "  color: #0a58ca;\n",
       "}\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "<table class=\"repr table table-hover table-striped table-sm table-responsive small\">\n",
       "    \n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "<tr class=\"repr-section-header general-360fb9cd-dfe1-42db-a49c-88be5c3e97e4\"  title=\"Hide section\" \n",
       "    onclick=\"toggleVisibility('general-360fb9cd-dfe1-42db-a49c-88be5c3e97e4')\">\n",
       "    <th class=\"repr-section-toggle-col\">\n",
       "        <button>\n",
       "            \n",
       "            <span class=\"collapse-uncollapse-caret\"></span>\n",
       "        </button>\n",
       "    </th>\n",
       "    <th colspan=\"2\">\n",
       "        <strong>General</strong>\n",
       "    </th>\n",
       "</tr>\n",
       "\n",
       "<tr class=\"repr-element general-360fb9cd-dfe1-42db-a49c-88be5c3e97e4 \">\n",
       "    <td class=\"repr-section-toggle-col\"></td>\n",
       "    <td>MNE object type</td>\n",
       "    <td>Info</td>\n",
       "</tr>\n",
       "<tr class=\"repr-element general-360fb9cd-dfe1-42db-a49c-88be5c3e97e4 \">\n",
       "    <td class=\"repr-section-toggle-col\"></td>\n",
       "    <td>Measurement date</td>\n",
       "    \n",
       "    <td>2076-11-06 at 11:42:54 UTC</td>\n",
       "    \n",
       "</tr>\n",
       "<tr class=\"repr-element general-360fb9cd-dfe1-42db-a49c-88be5c3e97e4 \">\n",
       "    <td class=\"repr-section-toggle-col\"></td>\n",
       "    <td>Participant</td>\n",
       "    \n",
       "    \n",
       "    <td>Surrogate</td>\n",
       "    \n",
       "    \n",
       "</tr>\n",
       "<tr class=\"repr-element general-360fb9cd-dfe1-42db-a49c-88be5c3e97e4 \">\n",
       "    <td class=\"repr-section-toggle-col\"></td>\n",
       "    <td>Experimenter</td>\n",
       "    \n",
       "    <td>Unknown</td>\n",
       "    \n",
       "</tr>\n",
       "    \n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "<tr class=\"repr-section-header acquisition-31d3ac72-c740-4c96-8608-eeaed29edf87\" \n",
       "    title=\"Hide section\"  onclick=\"toggleVisibility('acquisition-31d3ac72-c740-4c96-8608-eeaed29edf87')\">\n",
       "    <th class=\"repr-section-toggle-col\">\n",
       "        <button>\n",
       "            \n",
       "            <span class=\"collapse-uncollapse-caret\"></span>\n",
       "        </button>\n",
       "    </th>\n",
       "    <th colspan=\"2\">\n",
       "        <strong>Acquisition</strong>\n",
       "    </th>\n",
       "</tr>\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "<tr class=\"repr-element acquisition-31d3ac72-c740-4c96-8608-eeaed29edf87 \">\n",
       "    <td class=\"repr-section-toggle-col\"></td>\n",
       "    <td>Sampling frequency</td>\n",
       "    <td>256.00 Hz</td>\n",
       "</tr>\n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "<tr class=\"repr-section-header channels-c415c295-8402-41a4-beba-7d4259548177\"  title=\"Hide section\" \n",
       "    onclick=\"toggleVisibility('channels-c415c295-8402-41a4-beba-7d4259548177')\">\n",
       "    <th class=\"repr-section-toggle-col\">\n",
       "        <button>\n",
       "            \n",
       "            <span class=\"collapse-uncollapse-caret\"></span>\n",
       "        </button>\n",
       "    </th>\n",
       "    <th colspan=\"2\">\n",
       "        <strong>Channels</strong>\n",
       "    </th>\n",
       "</tr>\n",
       "\n",
       "\n",
       "<tr class=\"repr-element channels-c415c295-8402-41a4-beba-7d4259548177 \">\n",
       "    <td class=\"repr-section-toggle-col\"></td>\n",
       "    <td>EEG</td>\n",
       "    <td>\n",
       "        <button class=\"channel-names-btn\" onclick=\"alert('Good EEG:\\n\\nFP1-F7, F7-T7, T7-P7, P7-O1, FP1-F3, F3-C3, C3-P3, P3-O1, FP2-F4, F4-C4, C4-P4, P4-O2, FP2-F8, F8-T8, T8-P8-0, P8-O2, FZ-CZ, CZ-PZ, P7-T7, T7-FT9, FT9-FT10, FT10-T8, T8-P8-1')\" title=\"(Click to open in popup)&#13;&#13;FP1-F7, F7-T7, T7-P7, P7-O1, FP1-F3, F3-C3, C3-P3, P3-O1, FP2-F4, F4-C4, C4-P4, P4-O2, FP2-F8, F8-T8, T8-P8-0, P8-O2, FZ-CZ, CZ-PZ, P7-T7, T7-FT9, FT9-FT10, FT10-T8, T8-P8-1\">\n",
       "            23\n",
       "        </button>\n",
       "\n",
       "        \n",
       "    </td>\n",
       "</tr>\n",
       "\n",
       "\n",
       "<tr class=\"repr-element channels-c415c295-8402-41a4-beba-7d4259548177 \">\n",
       "    <td class=\"repr-section-toggle-col\"></td>\n",
       "    <td>Head & sensor digitization</td>\n",
       "    \n",
       "    <td>Not available</td>\n",
       "    \n",
       "</tr>\n",
       "    \n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "<tr class=\"repr-section-header filters-19daaa9f-225c-44d4-b559-b403656e3412\"  title=\"Hide section\" \n",
       "    onclick=\"toggleVisibility('filters-19daaa9f-225c-44d4-b559-b403656e3412')\">\n",
       "    <th class=\"repr-section-toggle-col\">\n",
       "        <button>\n",
       "            \n",
       "            <span class=\"collapse-uncollapse-caret\"></span>\n",
       "        </button>\n",
       "    </th>\n",
       "    <th colspan=\"2\">\n",
       "        <strong>Filters</strong>\n",
       "    </th>\n",
       "</tr>\n",
       "\n",
       "<tr class=\"repr-element filters-19daaa9f-225c-44d4-b559-b403656e3412 \">\n",
       "    <td class=\"repr-section-toggle-col\"></td>\n",
       "    <td>Highpass</td>\n",
       "    <td>0.00 Hz</td>\n",
       "</tr>\n",
       "\n",
       "\n",
       "<tr class=\"repr-element filters-19daaa9f-225c-44d4-b559-b403656e3412 \">\n",
       "    <td class=\"repr-section-toggle-col\"></td>\n",
       "    <td>Lowpass</td>\n",
       "    <td>128.00 Hz</td>\n",
       "</tr>\n",
       "\n",
       "\n",
       "</table>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "raw",
   "source": "Signal Extraction",
   "id": "b34f04b5a1b9c3e3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-15T13:37:43.096673Z",
     "start_time": "2024-12-15T13:37:43.069809Z"
    }
   },
   "cell_type": "code",
   "source": [
    "'''\n",
    "Reading EEG data, modified from cell 60 of notebook by Masahiro Gotoh   [available at https://www.kaggle.com/code/hemangjindal/chb-mit-eeg-dataset-my-notebook#CHB-MIT-eeg-dataset-seizure-detection-demo]\n",
    "'''\n",
    "# constants\n",
    "WINDOW_TIME = 8  # segment size in second\n",
    "STEP_TIME = 4     # Step size in second\n",
    "SAMPLING_RATE = 16  # EEG Sampling rate (Hz)\n",
    "SEIZURE_PROPORTION = 0.01    # proportion of non seizure, data is imbalanced with less than 1% comprising seizure data\n",
    "TO_MICROVOLTS = 1e6\n",
    "\n",
    "def read_edf(folder):\n",
    "    count=0\n",
    "    window_size=0\n",
    "\n",
    "    for file in folder:\n",
    "        edf_data = mne.io.read_raw_edf(file, preload=False)\n",
    "        edf_labels = edf_data.ch_names\n",
    "        # check all channel labels appear in edf_labels\n",
    "        if sum([any([0 if re.match(c, l) is None else 1 for l in edf_labels]) for c in channel_labels]) == len(channel_labels):\n",
    "            sampling_freq = int(1/(edf_data.times[1]-edf_data.times[0]))\n",
    "            window_size = sampling_freq * WINDOW_TIME\n",
    "            window_stride = sampling_freq * STEP_TIME\n",
    "\n",
    "            # identity EEG signal with seizure. 'Seizure' appended to file name, and marked at time point of seizure activity inside file.\n",
    "            # has seizure marks seizure/non-seizure as (1/0) for every data point\n",
    "            has_seizure = np.zeros((edf_data.n_times,))\n",
    "            if os.path.exists(file + '.seizures'):\n",
    "                has_annotation = wfdb.rdann(file, 'seizures')\n",
    "                # has_annotation.sample e.g [10,20, 300,400] means marked seizure from sample 10-20 , and 300-400\n",
    "                for idx in range(int(has_annotation.sample.size / 2)):\n",
    "                    has_seizure[has_annotation.sample[idx * 2]:has_annotation.sample[idx * 2 + 1]] = 1\n",
    "\n",
    "            #creawte seizure index, and calculate proportion of signal which shows seizures\n",
    "            is_seizure_idx = np.array([has_seizure[idx * window_stride:idx * window_stride + window_size].sum() / window_size for idx in range((edf_data.n_times - window_size) // window_stride)])\n",
    "\n",
    "            ### size of samples with and without seizure after subsampling\n",
    "            ### Data imbalance, normal EEG comprises 99% of data, multiplying by no seizure portion 0.01% allows downsampling of non seizure data\n",
    "            noseizure_n_size = round(SEIZURE_PROPORTION * np.where(is_seizure_idx==0)[0].size)\n",
    "            seizure_n_size = np.where(is_seizure_idx > 0)[0].size\n",
    "            count = count + noseizure_n_size + seizure_n_size\n",
    "        edf_data.close()\n",
    "\n",
    "    #initialise\n",
    "    signals_np = np.zeros((count, len(channel_labels), window_size), dtype=np.float32)\n",
    "    labels_seizure_np = np.zeros(count, dtype=bool)\n",
    "    return count, len(channel_labels), window_size"
   ],
   "id": "170c4f7d5af46834",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-14T05:48:13.141331Z",
     "start_time": "2024-12-14T05:48:13.113321Z"
    }
   },
   "cell_type": "code",
   "source": [
    "9\n",
    "def extract_edf2(folder, n_samples, n_channel_labels, window_size):\n",
    "    if os.path.exists(\"eeg_signals.npy\") and os.path.exists(\"seizure_labels.npy\"):\n",
    "        print(\"File eeg_signals.npy and seizure_labels.npy exists.\")\n",
    "        return\n",
    "    signals_np = np.zeros((n_samples, n_channel_labels, window_size), dtype=np.float32)\n",
    "    labels_np = np.zeros(n_samples, dtype=bool)\n",
    "\n",
    "\n",
    "    # Read  edf, rename file channel to match names from channel labels list. When files have multiple channel names, only first is picked.\n",
    "    for number, file in enumerate(tqdm.tqdm(folder)):\n",
    "        log = f\"Reading file {number} \"\n",
    "        edf_file = mne.io.read_raw_edf(file, preload=False)\n",
    "\n",
    "        n_label_match = sum([any([0 if re.match(ch, ch_name) is None else 1 for ch_name in edf_file.ch_names]) for ch in channel_labels])\n",
    "        if n_label_match == len(channel_labels):\n",
    "            dict_ch_name = {sorted([ch_name for ch_name in edf_file.ch_names if re.match(ch, ch_name) is not None])[0]: ch for ch in channel_labels}\n",
    "            edf_file.rename_channels(dict_ch_name)\n",
    "\n",
    "            # Retrieve EEG (in microvolts) ,  annotations\n",
    "            has_seizure = np.zeros((edf_file.n_times,))\n",
    "            signals_ = edf_file.get_data(picks=channel_labels) * TO_MICROVOLTS\n",
    "\n",
    "            if os.path.exists(file + '.seizures'):\n",
    "                log += \"positive seizure\"\n",
    "                has_annotation = wfdb.rdann(file, 'seizures')\n",
    "                for idx in range(int(has_annotation.sample.size / 2)):\n",
    "                    has_seizure[has_annotation.sample[idx * 2]:has_annotation.sample[idx * 2 + 1]] = 1\n",
    "            else:\n",
    "                log += \"negative seizure\"\n",
    "\n",
    "            # create seizure index, and calculate proportion of signal which shows seizures\n",
    "            sampling_freq = int(1/(edf_file.times[1] - edf_file.times[0]))\n",
    "            print(\"sampling frequency \",sampling_freq)\n",
    "            window_stride = int(sampling_freq * STEP_TIME)\n",
    "            print(f\"Window stride: {window_stride}, Window size: {window_size}\")\n",
    "            is_seizure_idx = np.array([has_seizure[idx * window_stride:idx * window_stride + window_size].sum() / window_size for idx in range((edf_file.n_times - window_size) // window_stride)])\n",
    "\n",
    "            # populate numpy array with EEG , annotation data\n",
    "            noseizure_n_size = round(SEIZURE_PROPORTION * np.where(is_seizure_idx == 0)[0].size)\n",
    "            seizure_n_size = np.where(is_seizure_idx > 0)[0].size\n",
    "\n",
    "\n",
    "            # non seizure data are by far larger than seizure data. To avoid overfitting, and bias, non seizure data is randomly subsampled. This prevents model from being overwhelmed by large non seizure data\n",
    "            count = 0\n",
    "            # no seizure\n",
    "            temp_negative = random.sample(list(np.where(is_seizure_idx == 0)[0]), noseizure_n_size)\n",
    "            for value in temp_negative:\n",
    "                start_idx = value * window_stride\n",
    "                end_idx = start_idx + window_size\n",
    "                segment = signals_[:, start_idx:end_idx]\n",
    "                print(f\"Segment shape: {segment.shape}\")  # Debug print\n",
    "                if segment.shape == (n_channel_labels, window_size):\n",
    "                    signals_np[count, :, :] = segment\n",
    "                    labels_np[count] = False\n",
    "                    count += 1\n",
    "                else:\n",
    "                    print(f\"Skipping segment due to shape mismatch: {segment.shape}\")\n",
    "\n",
    "            # seizure\n",
    "            temp_positive = list(np.where(is_seizure_idx > 0)[0])\n",
    "            for value in temp_positive:\n",
    "                start_idx = value * window_stride\n",
    "                end_idx = start_idx + window_size\n",
    "                segment = signals_[:, start_idx:end_idx]\n",
    "                print(f\"Segment shape: {segment.shape}\")  # Debug print\n",
    "                if segment.shape == (n_channel_labels, window_size):\n",
    "                    signals_np[count, :, :] = segment\n",
    "                    labels_np[count] = True\n",
    "                    count += 1\n",
    "                else:\n",
    "                    print(f\"Skipping segment due to shape mismatch: {segment.shape}\")\n",
    "\n",
    "            print(f\"{noseizure_n_size + seizure_n_size} EEG signals added {seizure_n_size} with, {noseizure_n_size} without seizures\")\n",
    "        else:\n",
    "            print(f\"Unable to read {file}\")\n",
    "\n",
    "        edf_file.close()\n",
    "\n",
    "    np.save('eeg_signals', signals_np)\n",
    "    np.save('seizure_labels', labels_np)\n",
    "\n"
   ],
   "id": "91163457e99061e4",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "sample_length, channel_length, window_length = read_edf(train_files)",
   "id": "9882507e4466fa14",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-15T13:54:18.900257Z",
     "start_time": "2024-12-15T13:54:18.510116Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#extract_edf(train_files, sample_length, channel_length, window_length)\n",
    "extract_edf2(train_files, sample_length, channel_length, window_length)"
   ],
   "id": "76fc334939722bab",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/523 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from C:\\Users\\mspla\\Documents\\repos\\py_basic_310_Au24\\seizurePy3.9\\data\\raw_data\\chb-mit-scalp-eeg-database-1.0.0\\chb01\\chb01_01.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mspla\\AppData\\Local\\Temp\\ipykernel_11760\\1130633979.py:8: RuntimeWarning: Channel names are not unique, found duplicates for: {'T8-P8'}. Applying running numbers for duplicates.\n",
      "  edf_file = mne.io.read_raw_edf(file, preload=False)\n",
      "  0%|          | 0/523 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampling frequency  256\n",
      "42\n",
      "signals_np (9529, 18, 2048)\n",
      "signals_ (18, 921600)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (18,0) into shape (18,2048)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[14], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mextract_edf\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_files\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msample_length\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mchannel_length\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mwindow_length\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[13], line 48\u001B[0m, in \u001B[0;36mextract_edf\u001B[1;34m(folder, n_samples, n_channel_labels, window_size)\u001B[0m\n\u001B[0;32m     46\u001B[0m start_index \u001B[38;5;241m=\u001B[39m value \u001B[38;5;241m*\u001B[39m window_size\n\u001B[0;32m     47\u001B[0m stop_index \u001B[38;5;241m=\u001B[39m value \u001B[38;5;241m*\u001B[39m window_stride \u001B[38;5;241m+\u001B[39m window_size\n\u001B[1;32m---> 48\u001B[0m signals_np[count, :, :] \u001B[38;5;241m=\u001B[39m signals_[:, start_index:stop_index ]\n\u001B[0;32m     49\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m45\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     50\u001B[0m labels_np[count] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "\u001B[1;31mValueError\u001B[0m: could not broadcast input array from shape (18,0) into shape (18,2048)"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "raw",
   "source": "",
   "id": "e1fe01556f81fab4",
   "outputs": null,
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-15T13:54:07.299448Z",
     "start_time": "2024-12-15T13:54:07.273855Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def extract_edf(folder, n_samples, n_channel_labels, window_size):\n",
    "    signals_np = np.zeros((n_samples, n_channel_labels, window_size), dtype=np.float32)\n",
    "    labels_np = np.zeros(n_samples, dtype=bool)\n",
    "\n",
    "    # Read  edf, rename file channel to match names from channel labels list. When files have multiple channel names, only first is picked.\n",
    "    for number, file in enumerate(tqdm.tqdm(folder)):\n",
    "        log = f\"Reading file {number} \"\n",
    "        edf_file = mne.io.read_raw_edf(file, preload=False)\n",
    "\n",
    "        n_label_match = sum([any([0 if re.match(ch, ch_name) is None else 1 for ch_name in edf_file.ch_names]) for ch in channel_labels])\n",
    "        if n_label_match == len(channel_labels):\n",
    "            dict_ch_name = {sorted([ch_name for ch_name in edf_file.ch_names if re.match(ch, ch_name) is not None])[0]: ch for ch in channel_labels}\n",
    "            edf_file.rename_channels(dict_ch_name)\n",
    "\n",
    "            # Retrieve EEG (in microvolts) ,  annotations\n",
    "            has_seizure = np.zeros((edf_file.n_times,))\n",
    "            signals_ = edf_file.get_data(picks=channel_labels) * TO_MICROVOLTS\n",
    "\n",
    "            if  os.path.exists(file+'.seizures'):\n",
    "                log = log + \"positive seizure\"\n",
    "                has_annotation = wfdb.rdann(file, 'seizures')\n",
    "                for idx in range(int(has_annotation.sample.size / 2)):\n",
    "                    has_seizure[has_annotation.sample[idx * 2]:has_annotation.sample[idx * 2 + 1]] = 1\n",
    "            else:\n",
    "                log = log + \"negative seizure\"\n",
    "\n",
    "            # create seizure index, and calculate proportion of signal which shows seizures\n",
    "            sampling_freq = int(1/(edf_file.times[1]-edf_file.times[0]))\n",
    "            print(\"sampling frequency \",sampling_freq)\n",
    "            window_stride = int(sampling_freq * STEP_TIME)\n",
    "            is_seizure_idx = np.array([has_seizure[idx * window_stride:idx * window_stride + window_size].sum() / window_size for idx in range((edf_file.n_times - window_size) // window_stride)])\n",
    "\n",
    "            # populate numpy array with EEG , annotation data\n",
    "            noseizure_n_size = round(SEIZURE_PROPORTION * np.where(is_seizure_idx==0)[0].size)\n",
    "            seizure_n_size = np.where(is_seizure_idx > 0)[0].size\n",
    "\n",
    "\n",
    "            # non seizure data are by far larger than seizure data. To avoid overfitting, and bias, non seizure data is randomly subsampled. This prevents model\n",
    "            # from being overwhelmed by large non seizure data\n",
    "            count = 0\n",
    "            temp_negative = random.sample(list(np.where(is_seizure_idx == 0)[0]), noseizure_n_size)\n",
    "            for value in temp_negative:\n",
    "                print(\"42\")\n",
    "                print(\"signals_np\",signals_np.shape)\n",
    "                print(\"signals_\",signals_.shape)\n",
    "                start_index = value * window_size\n",
    "                stop_index = value * window_stride + window_size\n",
    "                signals_np[count, :, :] = signals_[:, start_index:stop_index ]\n",
    "                print(\"45\")\n",
    "                labels_np[count] = False\n",
    "                count = count + 1\n",
    "            #seizure\n",
    "\n",
    "            temp_positive = list(np.where(is_seizure_idx == 1)[0])\n",
    "            for value in temp_positive:\n",
    "                start_index = value * window_stride\n",
    "                stop_index = value * window_stride + window_size\n",
    "                signals_np[count, :, :] = signals_[:, start_index: stop_index]\n",
    "                labels_np[count] = True\n",
    "                count = count + 1\n",
    "\n",
    "            print(f\"{noseizure_n_size+seizure_n_size} EEG signals added {seizure_n_size} with, {noseizure_n_size} without seizures\")\n",
    "        else:\n",
    "            print(f\"Unable to read {file}\")\n",
    "\n",
    "        # close resource\n",
    "        edf_file.close()\n",
    "\n",
    "        # save signal and label files\n",
    "    np.save('eeg_signals', signals_np)\n",
    "    np.save('seizure_labels', labels_np)\n",
    "\n"
   ],
   "id": "8374a0adad85c086",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "raw",
   "source": "Numpy format",
   "id": "2b58a696331b4fb3",
   "outputs": null,
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-14T05:49:15.593446Z",
     "start_time": "2024-12-14T05:49:14.979979Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 19,
   "source": [
    "path_signal = 'eeg_signals.npy'\n",
    "path_label = 'seizure_labels.npy'\n",
    "data_signals = np.load(path_signal)\n",
    "data_labels = np.load(path_label)"
   ],
   "id": "a27613cae92a2c7d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-14T05:49:15.641018Z",
     "start_time": "2024-12-14T05:49:15.629987Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9529, 18, 2048), (9529,))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 20,
   "source": "data_signals.shape,data_labels.shape",
   "id": "a128507273215948"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-14T05:49:16.358368Z",
     "start_time": "2024-12-14T05:49:16.345069Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 21,
   "source": [
    "n_samples, n_channels, segment_length = data_signals.shape\n",
    "n_labels = data_labels.shape[0]"
   ],
   "id": "69d552ce53d0ee48"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-14T05:49:17.060867Z",
     "start_time": "2024-12-14T05:49:17.049598Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numpy file eeg_signals.npy     has 9529   samples with 18 channels, and segment length of 2048\n",
      "Numpy file seizure_labels.npy  has 9529   labels for seizure presence or absence.\n"
     ]
    }
   ],
   "execution_count": 22,
   "source": [
    "print(f\"Numpy file {path_signal:<19} has {n_samples:<6} samples with {n_channels:} channels, and segment length of {segment_length}\")\n",
    "print(f\"Numpy file {path_label:<19} has {n_labels:<6} labels for seizure presence or absence.\")"
   ],
   "id": "48fc6d1f53a1078f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "# END",
   "id": "8f4966b8b0be5d54"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "7c1aef8abef019c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "e01573b4c75049d6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "'''\n",
    "\n",
    "# Configuration\n",
    "csv_folder = '/kaggle/working/csv_files'  # Folder containing the merged CSV file\n",
    "# eeg_channels = ['Channel_1', 'Channel_13', 'Channel_19', 'Channel_23']  # Channels to use\n",
    "eeg_channels = ['Channel_5', 'Channel_15', 'Channel_3', 'Channel_2']  # Channels to use\n",
    "\n",
    "window_size_sec = 5  # Window size in seconds\n",
    "step_size_sec = 2 # Step size in seconds\n",
    "sampling_rate = 16  # Sampling rate of EEG signals in Hz\n",
    "preictal_label = 1\n",
    "interictal_label = 0\n",
    "\n",
    "# Derived parameters\n",
    "window_size = window_size_sec * sampling_rate  # Convert to samples\n",
    "step_size = step_size_sec * sampling_rate  # Convert to samples\n",
    "\n",
    "# Function to load and prepare data\n",
    "def load_and_prepare_data(csv_file):\n",
    "    \"\"\"\n",
    "    Load the merged CSV data and prepare it for LSTM model training.\n",
    "    \"\"\"\n",
    "    data = pd.read_csv(csv_file)\n",
    "\n",
    "    # Normalize the EEG data (Min-Max scaling)\n",
    "    scaler = MinMaxScaler()\n",
    "    eeg_data = data[eeg_channels].values\n",
    "    eeg_data_scaled = scaler.fit_transform(eeg_data)\n",
    "\n",
    "    # Get the labels\n",
    "    labels = data['Label'].values\n",
    "\n",
    "    # Create sliding windows\n",
    "    windows, window_labels = create_windows(eeg_data_scaled, labels, window_size, step_size)\n",
    "\n",
    "    return windows, window_labels, scaler\n",
    "\n",
    "# Function to create windows from the data\n",
    "def create_windows(data, labels, window_size, step_size):\n",
    "    \"\"\"\n",
    "    Create overlapping windows from EEG data and corresponding labels.\n",
    "    \"\"\"\n",
    "    windows = []\n",
    "    window_labels = []\n",
    "\n",
    "    for start in range(0, len(data) - window_size + 1, step_size):\n",
    "        end = start + window_size\n",
    "        window = data[start:end, :]\n",
    "        label = labels[start:end]\n",
    "\n",
    "        # Assign label based on majority class in the window\n",
    "        window_label = preictal_label if np.sum(label == preictal_label) > len(label) // 2 else interictal_label\n",
    "        windows.append(window)\n",
    "        window_labels.append(window_label)\n",
    "\n",
    "    return np.array(windows), np.array(window_labels)\n",
    "\n",
    "# Function to build the LSTM model\n",
    "def build_lstm_model(input_shape):\n",
    "    \"\"\"\n",
    "    Build and compile an LSTM model.\n",
    "    \"\"\"\n",
    "    print('Input shape-',input_shape)\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=64, return_sequences=True, input_shape=input_shape))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(units=32, return_sequences=False))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(units=1, activation='sigmoid'))  # Output layer with sigmoid for binary classification\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Function to train the LSTM model\n",
    "def train_lstm_model(windows, window_labels):\n",
    "    \"\"\"\n",
    "    Train the LSTM model using the provided windows and labels.\n",
    "    \"\"\"\n",
    "    # Split data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(windows, window_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Build and train the model\n",
    "    model = build_lstm_model((X_train.shape[1], X_train.shape[2]))\n",
    "    model.fit(X_train, y_train, epochs=10, batch_size=64, validation_split=0.2)\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred = (y_pred > 0.5).astype(int)  # Convert probabilities to binary labels\n",
    "\n",
    "    # Print classification report\n",
    "    print(\"Classification Report on Test Data:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    # Return the trained model\n",
    "    return model, scaler\n",
    "\n",
    "# Real-time prediction function\n",
    "def real_time_prediction(model, scaler, window_size, interval=30):\n",
    "    \"\"\"\n",
    "    Simulate real-time predictions every `interval` seconds using the trained LSTM model.\n",
    "    \"\"\"\n",
    "    print(f\"Starting real-time prediction... (Interval: {interval}s)\")\n",
    "\n",
    "    # Simulate receiving new data (use the merged data as a placeholder)\n",
    "    while True:\n",
    "        # Simulate receiving data\n",
    "        # Replace this with real-time data fetching process\n",
    "        # For now, we assume the data is available in 'merged_df'\n",
    "        # Here we can simulate a chunk of data for prediction\n",
    "        simulated_data = np.random.rand(window_size, len(eeg_channels))  # Simulating new data\n",
    "\n",
    "        # Normalize the new data\n",
    "        scaled_data = scaler.transform(simulated_data)\n",
    "\n",
    "        # Reshape data to match LSTM input shape\n",
    "        X_input = scaled_data.reshape(1, window_size, len(eeg_channels))\n",
    "\n",
    "        # Predict the probability of seizure (preictal)\n",
    "        prediction = model.predict(X_input)\n",
    "        print(f\"Predicted probability of seizure: {prediction[0][0]:.4f}\")\n",
    "\n",
    "        # Sleep for the specified interval (simulate 30 seconds)\n",
    "        time.sleep(interval)\n",
    "\n",
    "# Main function\n",
    "if __name__ == \"__main__\":\n",
    "    # Load the merged data\n",
    "    csv_file = '/kaggle/working/csv_files/merged_data.csv'\n",
    "    windows, window_labels, scaler = load_and_prepare_data(csv_file)\n",
    "\n",
    "    # Train the LSTM model and evaluate on the test data\n",
    "    model, scaler = train_lstm_model(windows, window_labels)\n",
    "\n",
    "    # Save the model for later use\n",
    "    model.save('/kaggle/working/lstm_model.h5')\n",
    "    print(\"Model saved to /kaggle/working/lstm_model.h5\")\n",
    "\n",
    "    # Start real-time prediction\n",
    "    real_time_prediction(model, scaler, window_size, interval=30)\n",
    "\n",
    "'''"
   ],
   "id": "c3cbf0575d38d27"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "6646331cc1f543b7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T09:06:43.096280Z",
     "start_time": "2024-12-12T09:06:43.068658Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 21,
   "source": [
    "def read_edf(files_train):\n",
    "    time_window = 8\n",
    "    time_step = 4\n",
    "\n",
    "    if os.path.exists('/kaggle/input/mit-chb-processed/signal_samples.npy')&os.path.exists('/kaggle/input/mit-chb-processed/is_sz.npy'):\n",
    "        array_signals=np.load('/kaggle/input/mit-chb-processed/signal_samples.npy')\n",
    "        array_is_sz=np.load('/kaggle/input/mit-chb-processed/is_sz.npy')\n",
    "    else:\n",
    "        p = 0.01\n",
    "        counter = 0\n",
    "        step_window = 0\n",
    "        for temp_f in files_train:\n",
    "            temp_edf =  mne.io.read_raw_edf(temp_f)\n",
    "            temp_labels = temp_edf.ch_names\n",
    "            if sum([any([0 if re.match(c, l) is None else 1 for l in temp_edf.ch_names]) for c in ch_labels])==len(ch_labels):\n",
    "                time_window = 8\n",
    "                time_step = 4\n",
    "                fs = int(1/(temp_edf.times[1]-temp_edf.times[0]))\n",
    "                step_window = time_window*fs\n",
    "                step = time_step*fs\n",
    "\n",
    "                temp_is_sz = np.zeros((temp_edf.n_times,))\n",
    "                if os.path.exists(temp_f+'.seizures'):\n",
    "                    temp_annotation = wfdb.rdann(temp_f, 'seizures')\n",
    "                    for i in range(int(temp_annotation.sample.size/2)):\n",
    "                        temp_is_sz[temp_annotation.sample[i*2]:temp_annotation.sample[i*2+1]]=1\n",
    "                temp_len = temp_edf.n_times\n",
    "\n",
    "                temp_is_sz_ind = np.array(\n",
    "                    [temp_is_sz[i*step:i*step+step_window].sum()/step_window for i in range((temp_len-step_window)//step)]\n",
    "                )\n",
    "\n",
    "                temp_0_sample_size = round(p*np.where(temp_is_sz_ind==0)[0].size)\n",
    "                temp_1_sample_size = np.where(temp_is_sz_ind>0)[0].size\n",
    "\n",
    "                counter = counter + temp_0_sample_size + temp_1_sample_size\n",
    "            temp_edf.close()\n",
    "            return counter, ch_labels, step_window\n",
    "\n",
    "def extract_edf2(files_train, counter, ch_labels, step_window):\n",
    "        array_signals = np.zeros((counter, len(ch_labels), step_window), dtype=np.float32)\n",
    "        array_is_sz = np.zeros(counter, dtype=bool)\n",
    "\n",
    "        counter = 0\n",
    "        for n, temp_f in enumerate(tqdm.tqdm(files_train)):\n",
    "            to_log = 'No. {}: Reading. '.format(n)\n",
    "            temp_edf =  mne.io.read_raw_edf(temp_f)\n",
    "            temp_labels = temp_edf.ch_names\n",
    "            n_label_match = sum([any([0 if re.match(c, l)==None else 1 for l in temp_edf.ch_names]) for c in ch_labels])\n",
    "            if n_label_match==len(ch_labels):\n",
    "                ch_mapping = {sorted([l for l in temp_edf.ch_names if re.match(c, l)!=None ])[0]:c for c in ch_labels}\n",
    "                temp_edf.rename_channels(ch_mapping)\n",
    "                #temp_edf = temp_edf.pick(ch_labels)\n",
    "\n",
    "                temp_is_sz = np.zeros((temp_edf.n_times,))\n",
    "                temp_signals = temp_edf.get_data(picks=ch_labels)*1e6\n",
    "\n",
    "                if os.path.exists(temp_f+'.seizures'):\n",
    "                    to_log = to_log+'sz exists.'\n",
    "                    temp_annotation = wfdb.rdann(temp_f, 'seizures')\n",
    "                    for i in range(int(temp_annotation.sample.size/2)):\n",
    "                        temp_is_sz[temp_annotation.sample[i*2]:temp_annotation.sample[i*2+1]]=1\n",
    "                else:\n",
    "                    to_log = to_log+'No sz.'\n",
    "\n",
    "                temp_len = temp_edf.n_times\n",
    "\n",
    "                time_window = 8\n",
    "                time_step = 4\n",
    "                fs = int(1/(temp_edf.times[1]-temp_edf.times[0]))\n",
    "                step_window = time_window*fs\n",
    "                step = time_step*fs\n",
    "\n",
    "                temp_is_sz_ind = np.array(\n",
    "                    [temp_is_sz[i*step:i*step+step_window].sum()/step_window for i in range((temp_len-step_window)//step)]\n",
    "                )\n",
    "                del temp_is_sz\n",
    "\n",
    "                temp_0_sample_size = round(p*np.where(temp_is_sz_ind==0)[0].size)\n",
    "                temp_1_sample_size = np.where(temp_is_sz_ind>0)[0].size\n",
    "\n",
    "                # sz data\n",
    "                temp_ind = list(np.where(temp_is_sz_ind>0)[0])\n",
    "                for i in temp_ind:\n",
    "                    array_signals[counter, :, :] = temp_signals[:, i*step:i*step+step_window]\n",
    "                    array_is_sz[counter] = True\n",
    "                    counter = counter+1\n",
    "\n",
    "                # no sz data\n",
    "                temp_ind = random.sample(list(np.where(temp_is_sz_ind==0)[0]), temp_0_sample_size)\n",
    "                for i in temp_ind:\n",
    "                    array_signals[counter, :, :] = temp_signals[:, i*step:i*step+step_window]\n",
    "                    array_is_sz[counter] = False\n",
    "                    counter = counter+1\n",
    "\n",
    "                to_log += '{} signals added: {} w/o sz, {} w/ sz.'.format(\n",
    "                    temp_0_sample_size+temp_1_sample_size, temp_0_sample_size, temp_1_sample_size\n",
    "                )\n",
    "                print(\"array_signals\",array_signals.shape, array_signals[:2], \"temp_signals\",temp_signals.shape, temp_signals[:2])\n",
    "\n",
    "            else:\n",
    "                to_log += 'Not appropriate channel labels. Reading skipped.'.format(n)\n",
    "\n",
    "\n",
    "            temp_edf.close()\n",
    "\n",
    "        np.save('signal_samples', array_signals)\n",
    "        np.save('is_sz', array_is_sz)\n"
   ],
   "id": "d37772267146ba1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T09:06:44.637866Z",
     "start_time": "2024-12-12T09:06:44.611366Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from C:\\Users\\mspla\\Documents\\repos\\py_basic_310_Au24\\seizurePy3.9\\data\\raw_data\\chb-mit-scalp-eeg-database-1.0.0\\chb01\\chb01_01.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mspla\\AppData\\Local\\Temp\\ipykernel_6516\\519428527.py:13: RuntimeWarning: Channel names are not unique, found duplicates for: {'T8-P8'}. Applying running numbers for duplicates.\n",
      "  temp_edf =  mne.io.read_raw_edf(temp_f)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(9,\n",
       " ['FP1-F7',\n",
       "  'F7-T7',\n",
       "  'T7-P7',\n",
       "  'P7-O1',\n",
       "  'FP1-F3',\n",
       "  'F3-C3',\n",
       "  'C3-P3',\n",
       "  'P3-O1',\n",
       "  'FP2-F4',\n",
       "  'F4-C4',\n",
       "  'C4-P4',\n",
       "  'P4-O2',\n",
       "  'FP2-F8',\n",
       "  'F8-T8',\n",
       "  'T8-P8',\n",
       "  'P8-O2',\n",
       "  'FZ-CZ',\n",
       "  'CZ-PZ'],\n",
       " 2048)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 22,
   "source": [
    "count1, ch_labels1, step_window1 = read_edf(train_files)\n",
    "count1, channel_labels,step_window1\n",
    "#extract_edf2(train_files, count1, ch_labels1, step_window1)"
   ],
   "id": "b886c8c76c0d007"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T09:03:56.658898Z",
     "start_time": "2024-12-12T09:03:56.650716Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 16,
   "source": [
    "ch_labels = ['FP1-F7', 'F7-T7', 'T7-P7', 'P7-O1', 'FP1-F3', 'F3-C3', 'C3-P3','P3-O1',\n",
    "                  'FP2-F4', 'F4-C4', 'C4-P4', 'P4-O2', 'FP2-F8', 'F8-T8', 'T8-P8', 'P8-O2',\n",
    "                  'FZ-CZ', 'CZ-PZ']"
   ],
   "id": "56ea7528ae46397a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "test(train_files)",
   "id": "6b5bae98b4f673e3",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
