{
 "cells": [
  {
   "metadata": {},
   "cell_type": "raw",
   "source": [
    "Raw data are 42.6 GB in Edf format. Convert to csv for smaller size, and easier processing.\n",
    "1 Import mne and pandas library.\n",
    "2 mne.io.read_raw_edf to read each Edf file.\n",
    "3 mne.io.read_raw_edf.get_data to retrive read data.\n",
    "4 convert to numpy using  numpy.vstack. Vertical stack converts dimenstions into ssamples x features. This allow preprocessing\n",
    "5 save as csv using pandas.DataFrame.to_csv"
   ],
   "id": "9d8f5429570529c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-24T07:56:34.150102Z",
     "start_time": "2024-12-24T07:56:31.815665Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import mne # reads edf format\n",
    "import glob\n",
    "import random\n",
    "import re\n",
    "import wfdb # waveform database library wfdb.rdann reads annotation of physiology annotated data in ECG, EEG etc\n"
   ],
   "id": "9e3119ec8ee92a61",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "raw",
   "source": [
    "Retrive data from Edf file. EEG files are a montage of amplitudes from channels. Each channel represents scalp electrode detection of brain signal amplitude. The montage is arranged from left to right, and front of scalp to back.\n",
    "The channels are labelled as\n",
    "['FP1-F7', 'F7-T7', 'T7-P7', 'P7-O1', 'FP1-F3', 'F3-C3', 'C3-P3','P3-O1',\n",
    " 'FP2-F4', 'F4-C4', 'C4-P4', 'P4-O2', 'FP2-F8', 'F8-T8', 'T8-P8', 'P8-O2',\n",
    " 'FZ-CZ', 'CZ-PZ']\n"
   ],
   "id": "765460765ea4c7d4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "eee4dcb581eb2a2c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-24T06:32:53.753064Z",
     "start_time": "2024-12-24T06:32:53.737817Z"
    }
   },
   "cell_type": "code",
   "source": [
    "channel_labels = ['FP1-F7', 'F7-T7', 'T7-P7', 'P7-O1', 'FP1-F3', 'F3-C3', 'C3-P3','P3-O1',\n",
    "                  'FP2-F4', 'F4-C4', 'C4-P4', 'P4-O2', 'FP2-F8', 'F8-T8', 'T8-P8', 'P8-O2',\n",
    "                  'FZ-CZ', 'CZ-PZ']"
   ],
   "id": "d5fc00441f77703f",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "b1b3c51329149b5d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### The international 10-20 systems defines placement of scalp electrodes.\n",
    "Older system use 18 pairs or 18 channels\n",
    "Newer ones may have 23,24 or 26 pairs.\n",
    "For this project use 18 pairs or 18 channels.\n",
    "\n",
    "Furthermore some of the files have errors, including those with electrodes\n",
    "> ['PZ-P3', 'P3-P7', 'P7-P9',  'O2-O1',  'O1-O7'].\n",
    "\n",
    "Decision made to use 18 channels instead.\n"
   ],
   "id": "3e9fee2292681dbf"
  },
  {
   "metadata": {},
   "cell_type": "raw",
   "source": [
    "raw_data = \"raw_CHB-Mit\"\n",
    "patient name in filename ending with digit from chb01 - chb24"
   ],
   "id": "101877bfd0bfca0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-24T07:56:42.321370Z",
     "start_time": "2024-12-24T07:56:42.308734Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Each patient is assigned an integer from 0 to 24\n",
    "# Retrieve assigned patient number from file\n",
    "\n",
    "path = r'data\\raw_data\\chb-mit-scalp-eeg-database-1.0.0'\n",
    "data_folders = sorted(glob.glob(os.path.join(path, '*[0-9]')))\n",
    "\n",
    "def file_id(folder):\n",
    "    return [ name[-2:] for name in [file.rsplit('\\\\',2)[-1] for file in folder]]\n",
    "print(\"Case ID: \")\n",
    "print(file_id(data_folders))"
   ],
   "id": "b797d0c19547718a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Case ID: \n",
      "['01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24']\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-24T07:56:47.595658Z",
     "start_time": "2024-12-24T07:56:47.588423Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# seizure  marking is in name of edf file, not a separate file\n",
    "# split files for training and testing\n",
    "train_test_ratio = 0.8\n",
    "random.seed(80)\n",
    "train_folders = sorted(random.sample(data_folders, round(len(data_folders) * train_test_ratio)))\n",
    "test_folders = sorted([ file for file in data_folders if file not in train_folders])\n",
    "print(f\"train_folders' IDs: {file_id(train_folders)}, contains {len(train_folders)} files\")\n",
    "print(f\"test_folders' IDs: {file_id(test_folders)}, contains {len(test_folders)} files\")\n"
   ],
   "id": "2bc6e28cdb2717b3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_folders' IDs: ['01', '02', '04', '07', '08', '09', '10', '12', '13', '14', '15', '16', '17', '18', '19', '20', '22', '23', '24'], contains 19 files\n",
      "test_folders' IDs: ['03', '05', '06', '11', '21'], contains 5 files\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-24T07:56:52.308409Z",
     "start_time": "2024-12-24T07:56:52.294640Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Retrieve edf files\n",
    "\n",
    "train_files = [ file for folder in train_folders for file in glob.glob(folder+'/*.edf')]\n",
    "test_files = [ file for folder in test_folders for file in glob.glob(folder+'/*.edf')]\n",
    "\n",
    "print(f\"Train_files contains {len(train_files)} files\")\n",
    "print(f\"Test_files contains {len(test_files)} files\")\n",
    "print(f\"Random example from train_files: {random.choice(train_files)}\")\n"
   ],
   "id": "c918f7ef2f9a282f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_files contains 523 files\n",
      "Test_files contains 163 files\n",
      "Random example from train_files: data\\raw_data\\chb-mit-scalp-eeg-database-1.0.0\\chb01\\chb01_16.edf\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Raw files have duplicate files or files with duplicate names",
   "id": "cd21563f206e8d71"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-24T07:56:57.999441Z",
     "start_time": "2024-12-24T07:56:57.993399Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "73bf9703f3169dc0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-24T07:57:02.120351Z",
     "start_time": "2024-12-24T07:57:00.398353Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# MEG and EEG library (mne) reads neurophysiological data\n",
    "# dir(sample_edf)  # show all attributes and methods\n",
    "\n",
    "sample_edf = mne.io.read_raw_edf(train_files[0], preload=False) #110-15 seconds\n",
    "sample_edf.info"
   ],
   "id": "569762c98a1f7205",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from C:\\Users\\mspla\\Documents\\repos\\py_basic_310_Au24\\seizurePy3.9\\data\\raw_data\\chb-mit-scalp-eeg-database-1.0.0\\chb01\\chb01_01.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mspla\\AppData\\Local\\Temp\\ipykernel_14776\\2273869948.py:4: RuntimeWarning: Channel names are not unique, found duplicates for: {'T8-P8'}. Applying running numbers for duplicates.\n",
      "  sample_edf = mne.io.read_raw_edf(train_files[0], preload=False) #110-15 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Info | 8 non-empty values\n",
       " bads: []\n",
       " ch_names: FP1-F7, F7-T7, T7-P7, P7-O1, FP1-F3, F3-C3, C3-P3, P3-O1, ...\n",
       " chs: 23 EEG\n",
       " custom_ref_applied: False\n",
       " highpass: 0.0 Hz\n",
       " lowpass: 128.0 Hz\n",
       " meas_date: 2076-11-06 11:42:54 UTC\n",
       " nchan: 23\n",
       " projs: []\n",
       " sfreq: 256.0 Hz\n",
       " subject_info: 1 item (dict)\n",
       ">"
      ],
      "text/html": [
       "<script type=\"text/javascript\">\n",
       "    const toggleVisibility = (className) => {\n",
       "\n",
       "  const elements = document.querySelectorAll(`.${className}`)\n",
       "\n",
       "  elements.forEach(element => {\n",
       "    if (element.classList.contains('repr-section-header')) {\n",
       "      // Don't collapse the section header row.\n",
       "       return\n",
       "    }\n",
       "    if (element.classList.contains('repr-element-collapsed')) {\n",
       "      // Force a reflow to ensure the display change takes effect before removing the class\n",
       "      element.classList.remove('repr-element-collapsed')\n",
       "      element.offsetHeight // This forces the browser to recalculate layout\n",
       "      element.classList.remove('repr-element-faded')\n",
       "    } else {\n",
       "      // Start transition to hide the element\n",
       "      element.classList.add('repr-element-faded')\n",
       "      element.addEventListener('transitionend', handler = (e) => {\n",
       "        if (e.propertyName === 'opacity' && getComputedStyle(element).opacity === '0.2') {\n",
       "          element.classList.add('repr-element-collapsed')\n",
       "          element.removeEventListener('transitionend', handler)\n",
       "        }\n",
       "      });\n",
       "    }\n",
       "  });\n",
       "\n",
       "  // Take care of button (adjust caret)\n",
       "  const button = document.querySelectorAll(`.repr-section-header.${className} > th.repr-section-toggle-col > button`)[0]\n",
       "  button.classList.toggle('collapsed')\n",
       "\n",
       "  // Take care of the tooltip of the section header row\n",
       "  const sectionHeaderRow = document.querySelectorAll(`tr.repr-section-header.${className}`)[0]\n",
       "  sectionHeaderRow.classList.toggle('collapsed')\n",
       "  sectionHeaderRow.title = sectionHeaderRow.title === 'Hide section' ? 'Show section' : 'Hide section'\n",
       "}\n",
       "</script>\n",
       "\n",
       "<style type=\"text/css\">\n",
       "    table.repr.table.table-hover.table-striped.table-sm.table-responsive.small {\n",
       "  /* Don't make rows wider than they need to be. */\n",
       "  display: inline;\n",
       "}\n",
       "\n",
       "table > tbody > tr.repr-element > td {\n",
       "  /* Apply a tighter layout to the table cells. */\n",
       "  padding-top: 0.1rem;\n",
       "  padding-bottom: 0.1rem;\n",
       "  padding-right: 1rem;\n",
       "}\n",
       "\n",
       "table > tbody > tr > td.repr-section-toggle-col {\n",
       "  /* Remove background and border of the first cell in every row\n",
       "     (this row is only used for the collapse / uncollapse caret)\n",
       "\n",
       "     TODO: Need to find a good solution for VS Code that works in both\n",
       "           light and dark mode. */\n",
       "  border-color: transparent;\n",
       "  --bs-table-accent-bg: transparent;\n",
       "}\n",
       "\n",
       "tr.repr-section-header {\n",
       "  /* Remove stripes from section header rows */\n",
       "  background-color: transparent;\n",
       "  border-color: transparent;\n",
       "  --bs-table-striped-bg: transparent;\n",
       "  cursor: pointer;\n",
       "}\n",
       "\n",
       "tr.repr-section-header > th {\n",
       "  text-align: left !important;\n",
       "  vertical-align: middle;\n",
       "}\n",
       "\n",
       ".repr-element, tr.repr-element > td {\n",
       "  opacity: 1;\n",
       "  text-align: left !important;\n",
       "}\n",
       "\n",
       ".repr-element-faded {\n",
       "  transition: 0.3s ease;\n",
       "  opacity: 0.2;\n",
       "}\n",
       "\n",
       ".repr-element-collapsed {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "/* Collapse / uncollapse button and the caret it contains. */\n",
       ".repr-section-toggle-col button {\n",
       "  cursor: pointer;\n",
       "  width: 1rem;\n",
       "  background-color: transparent;\n",
       "  border-color: transparent;\n",
       "}\n",
       "\n",
       "span.collapse-uncollapse-caret {\n",
       "  width: 1rem;\n",
       "  height: 1rem;\n",
       "  display: block;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: left;\n",
       "  background-size: contain;\n",
       "}\n",
       "\n",
       "/* The collapse / uncollapse carets were copied from the free Font Awesome collection and adjusted. */\n",
       "\n",
       "/* Default to black carets for light mode */\n",
       ".repr-section-toggle-col > button.collapsed > span.collapse-uncollapse-caret {\n",
       "  background-image: url('data:image/svg+xml;charset=utf8,<svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 256 512\"><!--!Font Awesome Free 6.5.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free Copyright 2024 Fonticons, Inc.--><path fill=\"black\" d=\"M246.6 278.6c12.5-12.5 12.5-32.8 0-45.3l-128-128c-9.2-9.2-22.9-11.9-34.9-6.9s-19.8 16.6-19.8 29.6l0 256c0 12.9 7.8 24.6 19.8 29.6s25.7 2.2 34.9-6.9l128-128z\"/></svg>');\n",
       "}\n",
       "\n",
       ".repr-section-toggle-col\n",
       "  > button:not(.collapsed)\n",
       "  > span.collapse-uncollapse-caret {\n",
       "  background-image: url('data:image/svg+xml;charset=utf8,<svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 320 512\"><!--!Font Awesome Free 6.5.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free Copyright 2024 Fonticons, Inc.--><path fill=\"black\" d=\"M137.4 374.6c12.5 12.5 32.8 12.5 45.3 0l128-128c9.2-9.2 11.9-22.9 6.9-34.9s-16.6-19.8-29.6-19.8L32 192c-12.9 0-24.6 7.8-29.6 19.8s-2.2 25.7 6.9 34.9l128 128z\"/></svg>');\n",
       "}\n",
       "\n",
       "/* Use white carets for dark mode */\n",
       "@media (prefers-color-scheme: dark) {\n",
       "  .repr-section-toggle-col > button.collapsed > span.collapse-uncollapse-caret {\n",
       "    background-image: url('data:image/svg+xml;charset=utf8,<svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 256 512\"><!--!Font Awesome Free 6.5.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free Copyright 2024 Fonticons, Inc.--><path fill=\"white\" d=\"M246.6 278.6c12.5-12.5 12.5-32.8 0-45.3l-128-128c-9.2-9.2-22.9-11.9-34.9-6.9s-19.8 16.6-19.8 29.6l0 256c0 12.9 7.8 24.6 19.8 29.6s25.7 2.2 34.9-6.9l128-128z\"/></svg>');\n",
       "  }\n",
       "\n",
       "  .repr-section-toggle-col\n",
       "    > button:not(.collapsed)\n",
       "    > span.collapse-uncollapse-caret {\n",
       "    background-image: url('data:image/svg+xml;charset=utf8,<svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 320 512\"><!--!Font Awesome Free 6.5.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free Copyright 2024 Fonticons, Inc.--><path fill=\"white\" d=\"M137.4 374.6c12.5 12.5 32.8 12.5 45.3 0l128-128c9.2-9.2 11.9-22.9 6.9-34.9s-16.6-19.8-29.6-19.8L32 192c-12.9 0-24.6 7.8-29.6 19.8s-2.2 25.7 6.9 34.9l128 128z\"/></svg>');\n",
       "  }\n",
       "}\n",
       "\n",
       ".channel-names-btn {\n",
       "  padding: 0;\n",
       "  border: none;\n",
       "  background: none;\n",
       "  text-decoration: underline;\n",
       "  text-decoration-style: dashed;\n",
       "  cursor: pointer;\n",
       "  color: #0d6efd;\n",
       "}\n",
       "\n",
       ".channel-names-btn:hover {\n",
       "  color: #0a58ca;\n",
       "}\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "<table class=\"repr table table-hover table-striped table-sm table-responsive small\">\n",
       "    \n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "<tr class=\"repr-section-header general-901b8f8f-4caa-4129-90e2-0064001b7f44\"  title=\"Hide section\" \n",
       "    onclick=\"toggleVisibility('general-901b8f8f-4caa-4129-90e2-0064001b7f44')\">\n",
       "    <th class=\"repr-section-toggle-col\">\n",
       "        <button>\n",
       "            \n",
       "            <span class=\"collapse-uncollapse-caret\"></span>\n",
       "        </button>\n",
       "    </th>\n",
       "    <th colspan=\"2\">\n",
       "        <strong>General</strong>\n",
       "    </th>\n",
       "</tr>\n",
       "\n",
       "<tr class=\"repr-element general-901b8f8f-4caa-4129-90e2-0064001b7f44 \">\n",
       "    <td class=\"repr-section-toggle-col\"></td>\n",
       "    <td>MNE object type</td>\n",
       "    <td>Info</td>\n",
       "</tr>\n",
       "<tr class=\"repr-element general-901b8f8f-4caa-4129-90e2-0064001b7f44 \">\n",
       "    <td class=\"repr-section-toggle-col\"></td>\n",
       "    <td>Measurement date</td>\n",
       "    \n",
       "    <td>2076-11-06 at 11:42:54 UTC</td>\n",
       "    \n",
       "</tr>\n",
       "<tr class=\"repr-element general-901b8f8f-4caa-4129-90e2-0064001b7f44 \">\n",
       "    <td class=\"repr-section-toggle-col\"></td>\n",
       "    <td>Participant</td>\n",
       "    \n",
       "    \n",
       "    <td>Surrogate</td>\n",
       "    \n",
       "    \n",
       "</tr>\n",
       "<tr class=\"repr-element general-901b8f8f-4caa-4129-90e2-0064001b7f44 \">\n",
       "    <td class=\"repr-section-toggle-col\"></td>\n",
       "    <td>Experimenter</td>\n",
       "    \n",
       "    <td>Unknown</td>\n",
       "    \n",
       "</tr>\n",
       "    \n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "<tr class=\"repr-section-header acquisition-04b4a38a-d68b-48c9-9451-8dbaee4876f0\" \n",
       "    title=\"Hide section\"  onclick=\"toggleVisibility('acquisition-04b4a38a-d68b-48c9-9451-8dbaee4876f0')\">\n",
       "    <th class=\"repr-section-toggle-col\">\n",
       "        <button>\n",
       "            \n",
       "            <span class=\"collapse-uncollapse-caret\"></span>\n",
       "        </button>\n",
       "    </th>\n",
       "    <th colspan=\"2\">\n",
       "        <strong>Acquisition</strong>\n",
       "    </th>\n",
       "</tr>\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "<tr class=\"repr-element acquisition-04b4a38a-d68b-48c9-9451-8dbaee4876f0 \">\n",
       "    <td class=\"repr-section-toggle-col\"></td>\n",
       "    <td>Sampling frequency</td>\n",
       "    <td>256.00 Hz</td>\n",
       "</tr>\n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "<tr class=\"repr-section-header channels-80f3c4d5-2a9d-48f4-b131-b68fb11ac084\"  title=\"Hide section\" \n",
       "    onclick=\"toggleVisibility('channels-80f3c4d5-2a9d-48f4-b131-b68fb11ac084')\">\n",
       "    <th class=\"repr-section-toggle-col\">\n",
       "        <button>\n",
       "            \n",
       "            <span class=\"collapse-uncollapse-caret\"></span>\n",
       "        </button>\n",
       "    </th>\n",
       "    <th colspan=\"2\">\n",
       "        <strong>Channels</strong>\n",
       "    </th>\n",
       "</tr>\n",
       "\n",
       "\n",
       "<tr class=\"repr-element channels-80f3c4d5-2a9d-48f4-b131-b68fb11ac084 \">\n",
       "    <td class=\"repr-section-toggle-col\"></td>\n",
       "    <td>EEG</td>\n",
       "    <td>\n",
       "        <button class=\"channel-names-btn\" onclick=\"alert('Good EEG:\\n\\nFP1-F7, F7-T7, T7-P7, P7-O1, FP1-F3, F3-C3, C3-P3, P3-O1, FP2-F4, F4-C4, C4-P4, P4-O2, FP2-F8, F8-T8, T8-P8-0, P8-O2, FZ-CZ, CZ-PZ, P7-T7, T7-FT9, FT9-FT10, FT10-T8, T8-P8-1')\" title=\"(Click to open in popup)&#13;&#13;FP1-F7, F7-T7, T7-P7, P7-O1, FP1-F3, F3-C3, C3-P3, P3-O1, FP2-F4, F4-C4, C4-P4, P4-O2, FP2-F8, F8-T8, T8-P8-0, P8-O2, FZ-CZ, CZ-PZ, P7-T7, T7-FT9, FT9-FT10, FT10-T8, T8-P8-1\">\n",
       "            23\n",
       "        </button>\n",
       "\n",
       "        \n",
       "    </td>\n",
       "</tr>\n",
       "\n",
       "\n",
       "<tr class=\"repr-element channels-80f3c4d5-2a9d-48f4-b131-b68fb11ac084 \">\n",
       "    <td class=\"repr-section-toggle-col\"></td>\n",
       "    <td>Head & sensor digitization</td>\n",
       "    \n",
       "    <td>Not available</td>\n",
       "    \n",
       "</tr>\n",
       "    \n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "<tr class=\"repr-section-header filters-b050585a-19f5-40a8-b843-bc01ea150e41\"  title=\"Hide section\" \n",
       "    onclick=\"toggleVisibility('filters-b050585a-19f5-40a8-b843-bc01ea150e41')\">\n",
       "    <th class=\"repr-section-toggle-col\">\n",
       "        <button>\n",
       "            \n",
       "            <span class=\"collapse-uncollapse-caret\"></span>\n",
       "        </button>\n",
       "    </th>\n",
       "    <th colspan=\"2\">\n",
       "        <strong>Filters</strong>\n",
       "    </th>\n",
       "</tr>\n",
       "\n",
       "<tr class=\"repr-element filters-b050585a-19f5-40a8-b843-bc01ea150e41 \">\n",
       "    <td class=\"repr-section-toggle-col\"></td>\n",
       "    <td>Highpass</td>\n",
       "    <td>0.00 Hz</td>\n",
       "</tr>\n",
       "\n",
       "\n",
       "<tr class=\"repr-element filters-b050585a-19f5-40a8-b843-bc01ea150e41 \">\n",
       "    <td class=\"repr-section-toggle-col\"></td>\n",
       "    <td>Lowpass</td>\n",
       "    <td>128.00 Hz</td>\n",
       "</tr>\n",
       "\n",
       "\n",
       "</table>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Signal Extraction\n",
    "\n",
    "Codes extensively modified from work by [Mashahiro Goton](https://www.kaggle.com/code/hemangjindal/chb-mit-eeg-dataset-my-notebook#CHB-MIT-eeg-dataset-seizure-detection-demo). [Online] [Accesssed on 20 October 2024]."
   ],
   "id": "85cc78864d88805b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-24T07:57:08.017460Z",
     "start_time": "2024-12-24T07:57:07.989182Z"
    }
   },
   "cell_type": "code",
   "source": [
    "'''\n",
    "Reading EEG data, modified from cell 60 of notebook by Masahiro Gotoh  [Online]\n",
    "[available at https://www.kaggle.com/code/hemangjindal/chb-mit-eeg-dataset-my-notebook#CHB-MIT-eeg-dataset-seizure-detection-demo]\n",
    "'''\n",
    "\n",
    "class EdfToNpy:\n",
    "    # constants\n",
    "    WINDOW_TIME = 10  # segment size in second\n",
    "    STEP_TIME = 4     # Step size in second\n",
    "    SEIZURE_PROPORTION = 0.01    # proportion of non seizure, data is imbalanced with less than 1% comprising seizure data, in term of total time from owner's documentations\n",
    "    TO_MICROVOLTS = 1e6\n",
    "    channel_labels = ['FP1-F7', 'F7-T7', 'T7-P7', 'P7-O1', 'FP1-F3', 'F3-C3', 'C3-P3','P3-O1',\n",
    "                      'FP2-F4', 'F4-C4', 'C4-P4', 'P4-O2', 'FP2-F8', 'F8-T8', 'T8-P8', 'P8-O2',\n",
    "                      'FZ-CZ', 'CZ-PZ']\n",
    "\n",
    "    def __init__(self, folder, save_to):\n",
    "        self.save_to = save_to\n",
    "        self.folder = folder\n",
    "\n",
    "\n",
    "    def read_edf(self):\n",
    "        count=0 # samples with seizure plus samples without seizure * seizure proportion (down sampling to try to balance both class)\n",
    "        window_size=0\n",
    "\n",
    "        for file in self.folder:\n",
    "            edf_data = mne.io.read_raw_edf(file, preload=False)\n",
    "            edf_labels = edf_data.ch_names\n",
    "            # check all channel labels appear in edf_labels\n",
    "            # acceptss files which have all the\n",
    "            if sum([any([0 if re.match(c, l) is None else 1 for l in edf_labels]) for c in EdfToNpy.channel_labels]) == len(EdfToNpy.channel_labels):\n",
    "                sampling_freq = int(1/(edf_data.times[1]-edf_data.times[0]))\n",
    "                window_size = sampling_freq * EdfToNpy.WINDOW_TIME\n",
    "                window_stride = sampling_freq * EdfToNpy.STEP_TIME\n",
    "\n",
    "                # identity EEG signal with seizure. 'Seizure' appended to file name, and marked at time point of seizure activity inside file.\n",
    "                # has seizure marks seizure/non-seizure as (1/0) for every data point. Its size equals number of data points\n",
    "                has_seizure = np.zeros((edf_data.n_times,))\n",
    "                if os.path.exists(file + '.seizures'):\n",
    "                    has_annotation = wfdb.rdann(file, 'seizures')\n",
    "                    # has_annotation.sample e.g [10,20, 300,400] means marked seizure from sample 10-20 , and 300-400 . [start1,end1, start2,end2, ...]]\n",
    "                    for idx in range(int(has_annotation.sample.size / 2)):\n",
    "                        has_seizure[has_annotation.sample[idx * 2]:has_annotation.sample[idx * 2 + 1]] = 1\n",
    "\n",
    "                # create has seizure index, and calculate proportion of signal which shows seizures\n",
    "                # if a window segment contains some seizure in signal, that window segment is classified as having 'seizure'\n",
    "                has_seizure_idx = np.array([has_seizure[idx * window_stride:idx * window_stride + window_size].sum() / window_size for idx in range((edf_data.n_times - window_size) // window_stride)])\n",
    "\n",
    "                ### size of samples with and without seizure after subsampling\n",
    "                ### Data imbalance, normal EEG comprises 99% of data, multiplying by no seizure portion 0.01% allows down sampling of non seizure data\n",
    "                # np.where returns tuple of array of indices , np.where()[0] returns array of indices\n",
    "                noseizure_n_size = round(EdfToNpy.SEIZURE_PROPORTION * np.where(has_seizure_idx==0)[0].size)\n",
    "                seizure_n_size = np.where(has_seizure_idx > 0)[0].size\n",
    "                count = count + noseizure_n_size + seizure_n_size\n",
    "            edf_data.close()\n",
    "\n",
    "        return count, len(EdfToNpy.channel_labels), window_size\n",
    "\n",
    "\n",
    "    def extract_edf(self, n_samples, n_channel_labels, window_size):\n",
    "        signals_np = np.zeros((n_samples, n_channel_labels, window_size), dtype=np.float32)\n",
    "        labels_np = np.zeros(n_samples, dtype=np.int32)\n",
    "\n",
    "        # Read  edf, rename file channel to match names from channel labels list. When files have multiple channel names, only first is picked.\n",
    "        for number, file in enumerate(self.folder):\n",
    "            log = f\"Reading file {number} \"\n",
    "            edf_data = mne.io.read_raw_edf(file, preload=False)\n",
    "\n",
    "            # accept edf files that have the pre-requisite channels as defined in EdfToNpy.channel_labels\n",
    "            n_label_match = sum([any([0 if re.match(ch, ch_name) is None else 1 for ch_name in edf_data.ch_names]) for ch in EdfToNpy.channel_labels])\n",
    "            if n_label_match == len(EdfToNpy.channel_labels):\n",
    "                # files may contain duplicate names\n",
    "                dict_ch_name = {sorted([ch_name for ch_name in edf_data.ch_names if re.match(ch, ch_name) is not None])[0]: ch for ch in EdfToNpy.channel_labels}\n",
    "                edf_data.rename_channels(dict_ch_name)\n",
    "\n",
    "                # Retrieve EEG (in microvolts) ,  annotations\n",
    "                has_seizure = np.zeros((edf_data.n_times,))\n",
    "                signals_ = edf_data.get_data(picks=EdfToNpy.channel_labels) * EdfToNpy.TO_MICROVOLTS\n",
    "\n",
    "                if  os.path.exists(file+'.seizures'):\n",
    "                    log = log + \"positive seizure\"\n",
    "                    has_annotation = wfdb.rdann(file, 'seizures')\n",
    "                    for idx in range(int(has_annotation.sample.size / 2)):\n",
    "                        has_seizure[has_annotation.sample[idx * 2]:has_annotation.sample[idx * 2 + 1]] = 1\n",
    "                else:\n",
    "                    log = log + \"negative seizure\"\n",
    "\n",
    "                # create seizure index, and calculate proportion of signal which shows seizures\n",
    "                sampling_freq = int(1/(edf_data.times[1]-edf_data.times[0]))\n",
    "                window_size = sampling_freq * EdfToNpy.WINDOW_TIME\n",
    "\n",
    "                window_stride = sampling_freq * EdfToNpy.STEP_TIME\n",
    "                has_seizure_idx = np.array([has_seizure[idx * window_stride:idx * window_stride + window_size].sum() / window_size for idx in range((edf_data.n_times - window_size) // window_stride)])\n",
    "\n",
    "                # populate numpy array with EEG , annotation data\n",
    "                noseizure_n_size = round(EdfToNpy.SEIZURE_PROPORTION * np.where(has_seizure_idx==0)[0].size)\n",
    "                seizure_n_size = np.where(has_seizure_idx > 0)[0].size\n",
    "\n",
    "\n",
    "                # non seizure data are by far larger than seizure data. To avoid overfitting, and bias, non seizure data is randomly subsampled. This prevents model\n",
    "                # from being overwhelmed by large non seizure data\n",
    "                count = 0\n",
    "                temp_negative = random.sample(list(np.where(has_seizure_idx == 0)[0]), noseizure_n_size)\n",
    "                for value in temp_negative:\n",
    "                    start_index = value * window_stride\n",
    "                    stop_index = value * window_stride + window_size\n",
    "                    signals_np[count, :, :] = signals_[:, start_index:stop_index ]\n",
    "\n",
    "                    labels_np[count] = 0\n",
    "                    count = count + 1\n",
    "                #seizure\n",
    "\n",
    "                temp_positive = list(np.where(has_seizure_idx > 0)[0])\n",
    "                for value in temp_positive:\n",
    "                    start_index = value * window_stride\n",
    "                    stop_index = value * window_stride + window_size\n",
    "                    signals_np[count, :, :] = signals_[:, start_index: stop_index]\n",
    "                    labels_np[count] = 1\n",
    "                    count = count + 1\n",
    "\n",
    "                #print(f\"{noseizure_n_size+seizure_n_size} EEG signals added {seizure_n_size} with, {noseizure_n_size} without seizures\")\n",
    "            else:\n",
    "                print(f\"Unable to read {file}\")\n",
    "\n",
    "            # close resource\n",
    "            edf_data.close()\n",
    "\n",
    "            # save signal and label files\n",
    "        np.save(self.save_to + '_signals', signals_np)\n",
    "        np.save(self.save_to + '_labels', labels_np)\n",
    "\n",
    "\n",
    "        def show_eeg(self, signals):\n",
    "            # show a sample of extracted signals (the last one)\n",
    "\n",
    "            vertical_width = 250\n",
    "            fs = 256\n",
    "\n",
    "            fig, ax = plt.subplots()\n",
    "            for i in range(signals.shape[0]):\n",
    "                ax.plot(np.arange(signals.shape[-1])/fs, signals[i, :]+i*vertical_width, linewidth=0.5, color='tab:blue')\n",
    "                ax.annotate(EdfToNpy.channel_labels[i], xy=(0, i*vertical_width))\n",
    "            ax.invert_yaxis()\n",
    "            plt.show()\n"
   ],
   "id": "170c4f7d5af46834",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "raw",
   "source": [
    "def extract_edf(folder, n_samples, n_channel_labels, window_size):\n",
    "    signals_np = np.zeros((n_samples, n_channel_labels, window_size), dtype=np.float32)\n",
    "    labels_np = np.zeros(n_samples, dtype=np.int32)\n",
    "\n",
    "    # Read  edf, rename file channel to match names from channel labels list. When files have multiple channel names, only first is picked.\n",
    "    for number, file in enumerate(folder):\n",
    "        log = f\"Reading file {number} \"\n",
    "        edf_data = mne.io.read_raw_edf(file, preload=False)\n",
    "\n",
    "        # accept edf files that have the pre-requisite channels as defined in EdfToNpy.channel_labels\n",
    "        n_label_match = sum([any([0 if re.match(ch, ch_name) is None else 1 for ch_name in edf_data.ch_names]) for ch in EdfToNpy.channel_labels])\n",
    "        if n_label_match == len(EdfToNpy.channel_labels):\n",
    "            # files may contain duplicate names\n",
    "            dict_ch_name = {sorted([ch_name for ch_name in edf_data.ch_names if re.match(ch, ch_name) is not None])[0]: ch for ch in EdfToNpy.channel_labels}\n",
    "            edf_data.rename_channels(dict_ch_name)\n",
    "\n",
    "            # Retrieve EEG (in microvolts) ,  annotations\n",
    "            has_seizure = np.zeros((edf_data.n_times,))\n",
    "            signals_ = edf_data.get_data(picks=EdfToNpy.channel_labels) * EdfToNpy.TO_MICROVOLTS\n",
    "\n",
    "            if  os.path.exists(file+'.seizures'):\n",
    "                log = log + \"positive seizure\"\n",
    "                has_annotation = wfdb.rdann(file, 'seizures')\n",
    "                for idx in range(int(has_annotation.sample.size / 2)):\n",
    "                    has_seizure[has_annotation.sample[idx * 2]:has_annotation.sample[idx * 2 + 1]] = 1\n",
    "            else:\n",
    "                log = log + \"negative seizure\"\n",
    "\n",
    "            # create seizure index, and calculate proportion of signal which shows seizures\n",
    "            sampling_freq = int(1/(edf_data.times[1]-edf_data.times[0]))\n",
    "            window_size = sampling_freq * EdfToNpy.WINDOW_TIME\n",
    "\n",
    "            window_stride = sampling_freq * EdfToNpy.STEP_TIME\n",
    "            has_seizure_idx = np.array([has_seizure[idx * window_stride:idx * window_stride + window_size].sum() / window_size for idx in range((edf_data.n_times - window_size) // window_stride)])\n",
    "\n",
    "            # populate numpy array with EEG , annotation data\n",
    "            noseizure_n_size = round(EdfToNpy.SEIZURE_PROPORTION * np.where(has_seizure_idx==0)[0].size)\n",
    "            seizure_n_size = np.where(has_seizure_idx > 0)[0].size\n",
    "\n",
    "\n",
    "            # non seizure data are by far larger than seizure data. To avoid overfitting, and bias, non seizure data is randomly subsampled. This prevents model\n",
    "            # from being overwhelmed by large non seizure data\n",
    "            count = 0\n",
    "            temp_negative = random.sample(list(np.where(has_seizure_idx == 0)[0]), noseizure_n_size)\n",
    "            for value in temp_negative:\n",
    "                start_index = value * window_stride\n",
    "                stop_index = value * window_stride + window_size\n",
    "                signals_np[count, :, :] = signals_[:, start_index:stop_index ]\n",
    "\n",
    "                labels_np[count] = 0\n",
    "                count = count + 1\n",
    "            #seizure\n",
    "\n",
    "            temp_positive = list(np.where(has_seizure_idx > 0)[0])\n",
    "            for value in temp_positive:\n",
    "                start_index = value * window_stride\n",
    "                stop_index = value * window_stride + window_size\n",
    "                signals_np[count, :, :] = signals_[:, start_index: stop_index]\n",
    "                labels_np[count] = 1\n",
    "                count = count + 1\n",
    "\n",
    "            #print(f\"{noseizure_n_size+seizure_n_size} EEG signals added {seizure_n_size} with, {noseizure_n_size} without seizures\")\n",
    "        else:\n",
    "            print(f\"Unable to read {file}\")\n",
    "\n",
    "        # close resource\n",
    "        edf_data.close()\n",
    "\n",
    "        # save signal and label files\n",
    "    np.save('10sec_signals', signals_np)\n",
    "    np.save('10sec_labels', labels_np)\n",
    "\n",
    "\n"
   ],
   "id": "1f055955e0d0676b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-24T07:57:17.657258Z",
     "start_time": "2024-12-24T07:57:17.643818Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Instantiate class\n",
    "train_npy =  EdfToNpy(train_files, 'train_10sec')\n",
    "\n",
    "# Get training samples\n",
    "sample_length, channel_length, window_length = train_npy.read_edf()\n",
    "train_npy.extract_edf(sample_length, channel_length, window_length)"
   ],
   "id": "e70d06a18215e13e",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "9882507e4466fa14",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-24T07:58:47.311444Z",
     "start_time": "2024-12-24T07:58:47.299585Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Instantiate class\n",
    "test_npy = EdfToNpy(test_files, 'test_10sec')\n",
    "# Get training samples\n",
    "sample_length, channel_length, window_length = test_npy.read_edf()\n",
    "test_npy.extract_edf(sample_length, channel_length, window_length)\n",
    "\n"
   ],
   "id": "76fc334939722bab",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "5cb348539ae0ff76",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "raw",
   "source": "",
   "id": "e1fe01556f81fab4",
   "outputs": null,
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-23T03:48:01.442144Z",
     "start_time": "2024-12-23T03:48:01.430607Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "d29e2ea3c681535c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Numpy format\n",
    "raw edf format parsed to  numpy format with each sample having 10-second window"
   ],
   "id": "1daa44fa3649e69c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-24T07:13:59.644586Z",
     "start_time": "2024-12-24T07:13:58.407434Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 24,
   "source": [
    "# Training data\n",
    "path_signal = 'train_10sec_signals.npy'\n",
    "path_label = 'train_10sec_labels.npy'\n",
    "train_signals = np.load(path_signal)\n",
    "train_labels = np.load(path_label)\n",
    "\n",
    "unique, count = np.unique(train_labels, return_counts=True)\n",
    "print(\"Train set\", unique, count)\n",
    "\n",
    "# Testing  data\n",
    "path_signal = 'test_10sec_signals.npy'\n",
    "path_label = 'test_10sec_labels.npy'\n",
    "test_signals = np.load(path_signal)\n",
    "test_labels = np.load(path_label)\n",
    "\n",
    "unique, count = np.unique(test_labels, return_counts=True)\n",
    "print(\"Test sample\",unique, count)\n",
    "\n"
   ],
   "id": "a27613cae92a2c7d"
  },
  {
   "metadata": {},
   "cell_type": "raw",
   "source": [
    "print(f\"Numpy file {path_signal:<19} has {n_samples:<6} samples with {n_channels:} channels, and segment length of {segment_length}\")\n",
    "print(f\"Numpy file {path_label:<19} has {n_labels:<6} labels \")"
   ],
   "id": "8276d2641967244e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Current train-test samples have been split by case number.\n",
    "\n",
    "as seizure episodes are distributed unevenly and small, such method of splitting may not be representative during classifier training.\n",
    "\n",
    "Chosen to convert all cases into single numpy data file and one numpy labels"
   ],
   "id": "96555c71e5719659"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-24T07:14:01.608856Z",
     "start_time": "2024-12-24T07:14:01.599718Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9597, 18, 2560), (9597,), (2493, 18, 2560), (2493,))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 25,
   "source": [
    "# Instantiate class\n",
    "data_npy = EdfToNpy(data_folders, '10sec')\n",
    "# Get training samples\n",
    "sample_length, channel_length, window_length = data_npy.read_edf()\n",
    "data_npy.extract_edf(sample_length, channel_length, window_length)"
   ],
   "id": "a128507273215948"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-24T06:45:01.002951Z",
     "start_time": "2024-12-24T06:45:00.972346Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "7dbb6776831848d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1] [9478  119]\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-24T07:14:37.159687Z",
     "start_time": "2024-12-24T07:14:37.145914Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "9381ce7067d9fbd4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1] [2307  186]\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "# END",
   "id": "8f4966b8b0be5d54"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "7c1aef8abef019c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "e01573b4c75049d6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "'''\n",
    "\n",
    "# Configuration\n",
    "csv_folder = '/kaggle/working/csv_files'  # Folder containing the merged CSV file\n",
    "# eeg_channels = ['Channel_1', 'Channel_13', 'Channel_19', 'Channel_23']  # Channels to use\n",
    "eeg_channels = ['Channel_5', 'Channel_15', 'Channel_3', 'Channel_2']  # Channels to use\n",
    "\n",
    "window_size_sec = 5  # Window size in seconds\n",
    "step_size_sec = 2 # Step size in seconds\n",
    "sampling_rate = 16  # Sampling rate of EEG signals in Hz\n",
    "preictal_label = 1\n",
    "interictal_label = 0\n",
    "\n",
    "# Derived parameters\n",
    "window_size = window_size_sec * sampling_rate  # Convert to samples\n",
    "step_size = step_size_sec * sampling_rate  # Convert to samples\n",
    "\n",
    "# Function to load and prepare data\n",
    "def load_and_prepare_data(csv_file):\n",
    "    \"\"\"\n",
    "    Load the merged CSV data and prepare it for LSTM model training.\n",
    "    \"\"\"\n",
    "    data = pd.read_csv(csv_file)\n",
    "\n",
    "    # Normalize the EEG data (Min-Max scaling)\n",
    "    scaler = MinMaxScaler()\n",
    "    eeg_data = data[eeg_channels].values\n",
    "    eeg_data_scaled = scaler.fit_transform(eeg_data)\n",
    "\n",
    "    # Get the labels\n",
    "    labels = data['Label'].values\n",
    "\n",
    "    # Create sliding windows\n",
    "    windows, window_labels = create_windows(eeg_data_scaled, labels, window_size, step_size)\n",
    "\n",
    "    return windows, window_labels, scaler\n",
    "\n",
    "# Function to create windows from the data\n",
    "def create_windows(data, labels, window_size, step_size):\n",
    "    \"\"\"\n",
    "    Create overlapping windows from EEG data and corresponding labels.\n",
    "    \"\"\"\n",
    "    windows = []\n",
    "    window_labels = []\n",
    "\n",
    "    for start in range(0, len(data) - window_size + 1, step_size):\n",
    "        end = start + window_size\n",
    "        window = data[start:end, :]\n",
    "        label = labels[start:end]\n",
    "\n",
    "        # Assign label based on majority class in the window\n",
    "        window_label = preictal_label if np.sum(label == preictal_label) > len(label) // 2 else interictal_label\n",
    "        windows.append(window)\n",
    "        window_labels.append(window_label)\n",
    "\n",
    "    return np.array(windows), np.array(window_labels)\n",
    "\n",
    "# Function to build the LSTM model\n",
    "def build_lstm_model(input_shape):\n",
    "    \"\"\"\n",
    "    Build and compile an LSTM model.\n",
    "    \"\"\"\n",
    "    print('Input shape-',input_shape)\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=64, return_sequences=True, input_shape=input_shape))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(units=32, return_sequences=False))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(units=1, activation='sigmoid'))  # Output layer with sigmoid for binary classification\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Function to train the LSTM model\n",
    "def train_lstm_model(windows, window_labels):\n",
    "    \"\"\"\n",
    "    Train the LSTM model using the provided windows and labels.\n",
    "    \"\"\"\n",
    "    # Split data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(windows, window_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Build and train the model\n",
    "    model = build_lstm_model((X_train.shape[1], X_train.shape[2]))\n",
    "    model.fit(X_train, y_train, epochs=10, batch_size=64, validation_split=0.2)\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred = (y_pred > 0.5).astype(int)  # Convert probabilities to binary labels\n",
    "\n",
    "    # Print classification report\n",
    "    print(\"Classification Report on Test Data:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    # Return the trained model\n",
    "    return model, scaler\n",
    "\n",
    "# Real-time prediction function\n",
    "def real_time_prediction(model, scaler, window_size, interval=30):\n",
    "    \"\"\"\n",
    "    Simulate real-time predictions every `interval` seconds using the trained LSTM model.\n",
    "    \"\"\"\n",
    "    print(f\"Starting real-time prediction... (Interval: {interval}s)\")\n",
    "\n",
    "    # Simulate receiving new data (use the merged data as a placeholder)\n",
    "    while True:\n",
    "        # Simulate receiving data\n",
    "        # Replace this with real-time data fetching process\n",
    "        # For now, we assume the data is available in 'merged_df'\n",
    "        # Here we can simulate a chunk of data for prediction\n",
    "        simulated_data = np.random.rand(window_size, len(eeg_channels))  # Simulating new data\n",
    "\n",
    "        # Normalize the new data\n",
    "        scaled_data = scaler.transform(simulated_data)\n",
    "\n",
    "        # Reshape data to match LSTM input shape\n",
    "        X_input = scaled_data.reshape(1, window_size, len(eeg_channels))\n",
    "\n",
    "        # Predict the probability of seizure (preictal)\n",
    "        prediction = model.predict(X_input)\n",
    "        print(f\"Predicted probability of seizure: {prediction[0][0]:.4f}\")\n",
    "\n",
    "        # Sleep for the specified interval (simulate 30 seconds)\n",
    "        time.sleep(interval)\n",
    "\n",
    "# Main function\n",
    "if __name__ == \"__main__\":\n",
    "    # Load the merged data\n",
    "    csv_file = '/kaggle/working/csv_files/merged_data.csv'\n",
    "    windows, window_labels, scaler = load_and_prepare_data(csv_file)\n",
    "\n",
    "    # Train the LSTM model and evaluate on the test data\n",
    "    model, scaler = train_lstm_model(windows, window_labels)\n",
    "\n",
    "    # Save the model for later use\n",
    "    model.save('/kaggle/working/lstm_model.h5')\n",
    "    print(\"Model saved to /kaggle/working/lstm_model.h5\")\n",
    "\n",
    "    # Start real-time prediction\n",
    "    real_time_prediction(model, scaler, window_size, interval=30)\n",
    "\n",
    "'''"
   ],
   "id": "c3cbf0575d38d27"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "6646331cc1f543b7",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
